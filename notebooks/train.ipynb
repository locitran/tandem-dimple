{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train.split_data import get_data\n",
    "from src.train.dataset import TANDEM_Dataset, get_test_data\n",
    "import torch\n",
    "from src.train.train import train_model\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from prody import LOGGER\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "config = {\n",
    "    'model': {\n",
    "        'input_shape': 33,\n",
    "        'n_hidden': 5,\n",
    "        # 'hidden_shape': 33,\n",
    "        'output_shape': 2,\n",
    "        'dropout': 0.2,\n",
    "    },\n",
    "    'train':{\n",
    "        'n_epochs': 300,\n",
    "        'patience': 50,\n",
    "        'batch_size': 256,\n",
    "        'lr': 1e-5,\n",
    "        'l1': 0,\n",
    "        'l2': 1e-4,\n",
    "        \n",
    "    },\n",
    "    'experiment_name': 'DNN',\n",
    "    'seed': 0,\n",
    "    'model_folder': 'logs/models',\n",
    "    'model_name': 'DNN',\n",
    "}\n",
    "\n",
    "clstr_path = './data/old/c30_clstr_May13_full_rhd.csv'\n",
    "feat_path = 'data/R20000/fReplaceDYN_25Mar19.csv'\n",
    "\n",
    "GJB2_path = 'data/GJB2/fReplaceDYNandPfam_25Mar18.csv'\n",
    "RYR1_path = 'data/RYR1/fReplaceDYNandPfam_25Mar19.csv'\n",
    "sel_feats=['consurf', 'wt_PSIC', 'Delta_PSIC', 'entropy', 'ACNR', 'sasa', 'BLOSUM', 'stiffness-chain', 'loop_percent', 'atomic_1', 'vector_2', 'co_rank', 'atomic_3', 'atomic_5', 'Dcom', 'vector_1', 'rank_2', 'eig_first', 'ranked_MI', 'delta_h_bond_group', 'phobic_percent', 'eig_sec', 'sheet_percent', 'gyradius', 'delta_polarity', 'side_chain_length', 'helix_percent', 'delta_side_chain_length', 'ANM_effectiveness-chain', 'rank_1', 'rmsf_overall', 'delta_charge', 'delta_phobic_percent']\n",
    "config['model']['input_shape'] = len(sel_feats)\n",
    "config['experiment_name'] = f'{len(sel_feats)}_features'\n",
    "os.makedirs(f'logs/{config[\"experiment_name\"]}', exist_ok=True)\n",
    "LOGGER.start(f'logs/{config[\"experiment_name\"]}/train.log')\n",
    "LOGGER.info(f'Features: {sel_feats}')\n",
    "\n",
    "folds, preprocess_feat = get_data(feat_path, clstr_path, sel_feats=sel_feats,_plot='ratio_description.png', folds='folds.pkl')\n",
    "gjb2_data = get_test_data(GJB2_path, sel_feats, preprocess_feat, name='GJB2')\n",
    "ryr1_data = get_test_data(RYR1_path, sel_feats, preprocess_feat, name='RYR1')\n",
    "gjb2_VUS_ds = TANDEM_Dataset(gjb2_data['VUS'])\n",
    "gjb2_notVUS_ds = TANDEM_Dataset(gjb2_data['notVUS'])\n",
    "ryr1_VUS_ds = TANDEM_Dataset(ryr1_data['VUS'])\n",
    "ryr1_notVUS_ds = TANDEM_Dataset(ryr1_data['notVUS'])\n",
    "\n",
    "gjb2_VUS_loader = torch.utils.data.DataLoader(gjb2_VUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "gjb2_notVUS_loader = torch.utils.data.DataLoader(gjb2_notVUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "ryr1_VUS_loader = torch.utils.data.DataLoader(ryr1_VUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "ryr1_notVUS_loader = torch.utils.data.DataLoader(ryr1_notVUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "\n",
    "for i in range(5):\n",
    "    writer = SummaryWriter(log_dir=f'logs/{config[\"experiment_name\"]}/fold_{i}')\n",
    "    train_ds = TANDEM_Dataset(folds[i]['train'])\n",
    "    val_ds = TANDEM_Dataset(folds[i]['val'])\n",
    "    test_ds = TANDEM_Dataset(folds[i]['test'])\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=config['train']['batch_size'], shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "    # Estimate the initial bias\n",
    "    pos = np.sum(folds[i]['train'][1]==1)\n",
    "    neg = np.sum(folds[i]['train'][1]==0)\n",
    "    initial_bias = np.log([pos/neg])\n",
    "    # convert to tensor\n",
    "    initial_bias = torch.tensor(initial_bias, dtype=torch.float)\n",
    "    LOGGER.info(f'Initial bias: {initial_bias}')\n",
    "    train_model(config, train_loader, val_loader, \n",
    "                [test_loader, gjb2_notVUS_loader, ryr1_notVUS_loader],\n",
    "                ['test', 'GJB2', 'RYR1'],\n",
    "                writer, output_bias=initial_bias)\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type str doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m sel = df2.loc[df2[\u001b[33m'\u001b[39m\u001b[33mSAV_coords\u001b[39m\u001b[33m'\u001b[39m] == sav]\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     df1_feat = \u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     df2_feat = \u001b[38;5;28mround\u001b[39m(sel[feat].values[\u001b[32m0\u001b[39m], \u001b[32m4\u001b[39m)\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df1_feat != df2_feat:\n",
      "\u001b[31mTypeError\u001b[39m: type str doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = '/mnt/nas_1/YangLab/loci/tandem/data/RYR1/RYR1-features.csv'\n",
    "df2 = '/mnt/nas_1/YangLab/loci/tandem/data/RYR1/final_features.csv'\n",
    "\n",
    "df1 = pd.read_csv(df1)\n",
    "df2 = pd.read_csv(df2)\n",
    "cols = df1.columns.tolist()[1:]\n",
    "for i, row in df1.iterrows():\n",
    "    sav = row['SAV_coords']\n",
    "    sel = df2.loc[df2['SAV_coords'] == sav]\n",
    "    for feat in cols:\n",
    "        df1_feat = round(row[feat], 4)\n",
    "        df2_feat = round(sel[feat].values[0], 4)\n",
    "        if df1_feat != df2_feat:\n",
    "            print(f'Feature {feat} not equal for {sav}')\n",
    "            print(f'Row: {df1_feat}')\n",
    "            print(f'Sel: {df2_feat}')\n",
    "            # break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('/mnt/nas_1/YangLab/loci/tandem/data/RYR1/RYR1-features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAV_coords</th>\n",
       "      <th>labels</th>\n",
       "      <th>GNM_Ventropy_full</th>\n",
       "      <th>GNM_rmsf_overall_full</th>\n",
       "      <th>GNM_Eigval1_full</th>\n",
       "      <th>GNM_Eigval2_full</th>\n",
       "      <th>GNM_Eigval5_1_full</th>\n",
       "      <th>GNM_SEall_full</th>\n",
       "      <th>GNM_SE20_full</th>\n",
       "      <th>GNM_V1_full</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_phobic_percent</th>\n",
       "      <th>philic_percent</th>\n",
       "      <th>delta_philic_percent</th>\n",
       "      <th>charge</th>\n",
       "      <th>deltaCharge</th>\n",
       "      <th>polarity</th>\n",
       "      <th>deltaPolarity</th>\n",
       "      <th>charge_pH7</th>\n",
       "      <th>DELTA_charge_pH7</th>\n",
       "      <th>chain_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P21817 35 C R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P21817 44 R C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P21817 163 R C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P21817 163 R L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019849</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>-0.019849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P21817 248 G R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019849</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>0.019849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>P21817 4234 V L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>P21817 4737 R Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>P21817 4824 L P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>P21817 4893 R Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>P21817 4973 P L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7991.661</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.158794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SAV_coords  labels  GNM_Ventropy_full  GNM_rmsf_overall_full  \\\n",
       "0      P21817 35 C R     1.0           7991.661               0.729787   \n",
       "1      P21817 44 R C     1.0           7991.661               0.729787   \n",
       "2     P21817 163 R C     1.0           7991.661               0.729787   \n",
       "3     P21817 163 R L     1.0           7991.661               0.729787   \n",
       "4     P21817 248 G R     1.0           7991.661               0.729787   \n",
       "..               ...     ...                ...                    ...   \n",
       "115  P21817 4234 V L     NaN           7991.661               0.729787   \n",
       "116  P21817 4737 R Q     NaN           7991.661               0.729787   \n",
       "117  P21817 4824 L P     NaN           7991.661               0.729787   \n",
       "118  P21817 4893 R Q     NaN           7991.661               0.729787   \n",
       "119  P21817 4973 P L     NaN           7991.661               0.729787   \n",
       "\n",
       "     GNM_Eigval1_full  GNM_Eigval2_full  GNM_Eigval5_1_full  GNM_SEall_full  \\\n",
       "0            0.001179          0.001179             0.64386        0.898156   \n",
       "1            0.001179          0.001179             0.64386        0.898156   \n",
       "2            0.001179          0.001179             0.64386        0.898156   \n",
       "3            0.001179          0.001179             0.64386        0.898156   \n",
       "4            0.001179          0.001179             0.64386        0.898156   \n",
       "..                ...               ...                 ...             ...   \n",
       "115          0.001179          0.001179             0.64386        0.898156   \n",
       "116          0.001179          0.001179             0.64386        0.898156   \n",
       "117          0.001179          0.001179             0.64386        0.898156   \n",
       "118          0.001179          0.001179             0.64386        0.898156   \n",
       "119          0.001179          0.001179             0.64386        0.898156   \n",
       "\n",
       "     GNM_SE20_full  GNM_V1_full  ...  delta_phobic_percent  philic_percent  \\\n",
       "0         0.886682     0.003481  ...              0.000000       50.158794   \n",
       "1         0.886682     0.003692  ...              0.000000       50.158794   \n",
       "2         0.886682     0.003160  ...              0.000000       50.158794   \n",
       "3         0.886682     0.003160  ...              0.019849       50.158794   \n",
       "4         0.886682     0.004452  ...             -0.019849       50.158794   \n",
       "..             ...          ...  ...                   ...             ...   \n",
       "115       0.886682     0.002856  ...              0.000000       50.158794   \n",
       "116       0.886682     0.001312  ...              0.000000       50.158794   \n",
       "117       0.886682     0.000655  ...              0.000000       50.158794   \n",
       "118       0.886682     0.000060  ...              0.000000       50.158794   \n",
       "119       0.886682     0.003176  ...              0.000000       50.158794   \n",
       "\n",
       "     delta_philic_percent  charge  deltaCharge  polarity  deltaPolarity  \\\n",
       "0                0.000000     0.0          1.0       5.5            5.0   \n",
       "1                0.000000     1.0         -1.0      10.5           -5.0   \n",
       "2                0.000000     1.0         -1.0      10.5           -5.0   \n",
       "3               -0.019849     1.0         -1.0      10.5           -5.6   \n",
       "4                0.019849     0.0          1.0       9.0            1.5   \n",
       "..                    ...     ...          ...       ...            ...   \n",
       "115              0.000000     0.0          0.0       5.9           -1.0   \n",
       "116              0.000000     1.0         -1.0      10.5            0.0   \n",
       "117              0.000000     0.0          0.0       4.9            3.1   \n",
       "118              0.000000     1.0         -1.0      10.5            0.0   \n",
       "119              0.000000     0.0          0.0       8.0           -3.1   \n",
       "\n",
       "     charge_pH7  DELTA_charge_pH7  chain_length  \n",
       "0           0.0               1.0        4299.0  \n",
       "1           1.0              -1.0        4299.0  \n",
       "2           0.0               0.0        4299.0  \n",
       "3           0.0               0.0        4299.0  \n",
       "4           0.0               1.0        4299.0  \n",
       "..          ...               ...           ...  \n",
       "115         0.0               0.0        4299.0  \n",
       "116         1.0              -1.0        4299.0  \n",
       "117         0.0               0.0        4299.0  \n",
       "118         1.0              -1.0        4299.0  \n",
       "119         0.0               0.0        4299.0  \n",
       "\n",
       "[120 rows x 65 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /mnt/nas_1/YangLab/loci/tandem/logs/Optimization_Tandem_NumberOfLayers/20250415-1420/n_hidden-5/evaluations.csv\n",
    "from src.utils.settings import ROOT_DIR\n",
    "from prody import LOGGER\n",
    "import os\n",
    "import pandas as pd\n",
    "from src.train.split_data import split_data\n",
    "from src.train.split_data import dist_protein_level,  dist_cluster_level\n",
    "\n",
    "SAVs_path = os.path.join(ROOT_DIR, 'data/precomputed_features-ID_opt.tsv')\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/c30_clstr_May13_full_rhd.csv')\n",
    "savepath = os.path.join(ROOT_DIR, 'data/R20000/images')\n",
    "log = os.path.join(savepath, 'description.txt')\n",
    "LOGGER.start(log)\n",
    "folds = split_data(SAVs_path, clstr_path, folder=savepath)\n",
    "# Protein level\n",
    "SAVs_path = os.path.join(ROOT_DIR, 'data/precomputed_features-ID_opt.tsv')\n",
    "dist_protein_level(SAVs_path, folder='data/R20000')\n",
    "\n",
    "# Cluster level\n",
    "SAVs_path = os.path.join(ROOT_DIR, 'data/precomputed_features-ID_opt.tsv')\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/c30_clstr_May13_full_rhd.csv')\n",
    "dist_cluster_level(SAVs_path, clstr_path, folder='data/R20000')\n",
    "LOGGER.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train.split_data import get_data\n",
    "from src.utils.settings import ROOT_DIR\n",
    "import os \n",
    "from prody import LOGGER\n",
    "savepath = os.path.join(ROOT_DIR, 'data/R20000/images')\n",
    "sel_feats=['wtBJCE','deltaBJCE']\n",
    "feat_path = os.path.join(ROOT_DIR, 'data/R20000/features_withNEWpfam_25Mar25.csv')\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/c30_clstr_May13_full_rhd.csv')\n",
    "folds, preprocess_feat = get_data(feat_path, clstr_path, sel_feats=sel_feats,folder=savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.train.split_data import get_data, feature_correlation\n",
    "from src.utils.settings import ROOT_DIR\n",
    "import os \n",
    "import pandas as pd \n",
    "# from prody import LOGGER\n",
    "savepath = os.path.join(ROOT_DIR, 'data/R20000')\n",
    "feat_path = os.path.join(ROOT_DIR, 'data/R20000/features_withNEWpfam_25Mar25.csv')\n",
    "# feature_correlation(feat_path,folder=savepath)\n",
    "df = pd.read_csv(feat_path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head to feature_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train.split_data import get_data\n",
    "from src.utils.settings import ROOT_DIR\n",
    "import os \n",
    "from prody import LOGGER\n",
    "savepath = os.path.join(ROOT_DIR, 'data/R20000/images')\n",
    "sel_feats=['wtBJCE','deltaBJCE']\n",
    "feat_path = os.path.join(ROOT_DIR, 'data/R20000/features_withNEWpfam_25Mar25.csv')\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/c30_clstr_May13_full_rhd.csv')\n",
    "folds, preprocess_feat = get_data(feat_path, clstr_path, sel_feats=sel_feats,folder=savepath)\n",
    "\n",
    "\n",
    "from src.train.split_data import get_data\n",
    "from src.train.dataset import TANDEM_Dataset, get_test_data\n",
    "import torch\n",
    "from src.train.train import train_model\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import numpy as np\n",
    "from prody import LOGGER\n",
    "\n",
    "config = {\n",
    "    'model': {\n",
    "        'input_shape': 33,\n",
    "        'n_hidden': 5,\n",
    "        # 'hidden_shape': 33,\n",
    "        'output_shape': 2,\n",
    "        'dropout': 0,\n",
    "    },\n",
    "    'train':{\n",
    "        'n_epochs': 100,\n",
    "        'patience': 50,\n",
    "        'batch_size': 64,\n",
    "        'lr': 1e-4,\n",
    "        'l1': 0,\n",
    "        'l2': 1e-4,\n",
    "    },\n",
    "    'experiment_name': 'DNN',\n",
    "    'seed': 0,\n",
    "    'model_folder': 'logs/models',\n",
    "    'model_name': 'DNN',\n",
    "}\n",
    "LOGGER.start(f'logs/{config[\"experiment_name\"]}/train.log')\n",
    "\n",
    "clstr_path = './data/old/c30_clstr_May13_full_rhd.csv'\n",
    "feat_path = 'data/R20000/fReplaceDYN_25Mar19.csv'\n",
    "folds, preprocess_feat = get_data(feat_path, clstr_path, _plot='ratio_description.png', folds='folds.pkl')\n",
    "\n",
    "GJB2_path = 'data/GJB2/fReplaceDYNandPfam_25Mar18.csv'\n",
    "RYR1_path = 'data/RYR1/fReplaceDYNandPfam_25Mar19.csv'\n",
    "sel_feats=['consurf', 'wt_PSIC', 'Delta_PSIC', 'entropy', 'ACNR', 'sasa', 'BLOSUM', 'stiffness-chain', 'loop_percent', 'atomic_1', 'vector_2', 'co_rank', 'atomic_3', 'atomic_5', 'Dcom', 'vector_1', 'rank_2', 'eig_first', 'ranked_MI', 'delta_h_bond_group', 'phobic_percent', 'eig_sec', 'sheet_percent', 'gyradius', 'delta_polarity', 'side_chain_length', 'helix_percent', 'delta_side_chain_length', 'ANM_effectiveness-chain', 'rank_1', 'rmsf_overall', 'delta_charge', 'delta_phobic_percent']\n",
    "gjb2_data = get_test_data(GJB2_path, sel_feats, preprocess_feat, name='GJB2')\n",
    "ryr1_data = get_test_data(RYR1_path, sel_feats, preprocess_feat, name='RYR1')\n",
    "gjb2_VUS_ds = TANDEM_Dataset(gjb2_data['VUS'])\n",
    "gjb2_notVUS_ds = TANDEM_Dataset(gjb2_data['notVUS'])\n",
    "ryr1_VUS_ds = TANDEM_Dataset(ryr1_data['VUS'])\n",
    "ryr1_notVUS_ds = TANDEM_Dataset(ryr1_data['notVUS'])\n",
    "\n",
    "gjb2_VUS_loader = torch.utils.data.DataLoader(gjb2_VUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "gjb2_notVUS_loader = torch.utils.data.DataLoader(gjb2_notVUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "ryr1_VUS_loader = torch.utils.data.DataLoader(ryr1_VUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "ryr1_notVUS_loader = torch.utils.data.DataLoader(ryr1_notVUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "\n",
    "for i in range(5):\n",
    "    writer = SummaryWriter(log_dir=f'logs/{config[\"experiment_name\"]}/fold_{i}')\n",
    "    train_ds = TANDEM_Dataset(folds[i]['train'])\n",
    "    val_ds = TANDEM_Dataset(folds[i]['val'])\n",
    "    test_ds = TANDEM_Dataset(folds[i]['test'])\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=config['train']['batch_size'], shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "    # Estimate the initial bias\n",
    "    pos = len(folds[i]['train'][folds[i]['train']['label']==0])\n",
    "    neg = len(folds[i]['train'][folds[i]['train']['label']==1])\n",
    "    initial_bias = np.log([pos/neg])\n",
    "    LOGGER.info(f'Initial bias: {initial_bias}')\n",
    "    train_model(config, train_loader, val_loader, \n",
    "                [test_loader, gjb2_notVUS_loader, ryr1_notVUS_loader],\n",
    "                ['test', 'GJB2', 'RYR1'],\n",
    "                writer, output_bias=initial_bias)\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train.split_data import get_data\n",
    "from src.utils.settings import ROOT_DIR\n",
    "from src.train.dataset import TANDEM_Dataset, get_test_data\n",
    "from src.train.train import train_model\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from prody import LOGGER\n",
    "import os \n",
    "import torch\n",
    "config = {\n",
    "    'model': {\n",
    "        'input_shape': 33,\n",
    "        'n_hidden': 6,\n",
    "        'output_shape': 2,\n",
    "        'dropout': 0.,\n",
    "    },\n",
    "    'train':{\n",
    "        'n_epochs': 300,\n",
    "        'patience': 50,\n",
    "        'batch_size': 300,\n",
    "        'lr': 5e-5,\n",
    "        'l1': 0,\n",
    "        'l2': 1e-4,\n",
    "    },\n",
    "    'experiment_name': 'DNN',\n",
    "    'seed': 150,\n",
    "    'model_folder': 'logs/models',\n",
    "}\n",
    "os.makedirs(f'logs/{config[\"experiment_name\"]}', exist_ok=True)\n",
    "LOGGER.start(f'logs/{config[\"experiment_name\"]}/train.log')\n",
    "# input\n",
    "savepath = os.path.join(ROOT_DIR, 'data/R20000/images')\n",
    "feat_path = os.path.join(ROOT_DIR, 'data/R20000/features_withNEWpfam_25Mar25.csv')\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/c30_clstr_May13_full_rhd.csv')\n",
    "GJB2_path = os.path.join(ROOT_DIR, 'data/GJB2/features_25Mar27.csv')\n",
    "RYR1_path = os.path.join(ROOT_DIR, 'data/RYR1/features_25Mar26.csv')\n",
    "# selected features\n",
    "sel_feats = ['GNM_co_rank_reduced', 'ANM_stiffness_reduced', 'GNM_V1_reduced', \n",
    "'wtBJCE', 'GNM_V2_reduced', 'GNM_SEall_reduced', 'GNM_rankV2_reduced', \n",
    "'GNM_rankV1_reduced', 'GNM_SE20_reduced', 'GNM_Eigval2_reduced', \n",
    "'GNM_Eigval5_1_reduced', 'deltaBJCE', 'SASA', 'Dcom', 'loop_percent', 'AG1', 'AG5', 'AG3', 'SSbond', \n",
    "'Hbond', 'DELTA_DSS', 'DELTA_Hbond', 'sheet_percent', 'helix_percent', 'IDRs', \n",
    "'consurf', 'ACNR', 'wtPSIC', 'deltaPSIC', 'entropy', 'BLOSUM', 'ranked_MI', 'deltaPolarity']\n",
    "# get data\n",
    "folds, preprocess_feat = get_data(feat_path, clstr_path, sel_feats=sel_feats,folder=savepath)\n",
    "gjb2_data = get_test_data(GJB2_path, sel_feats, preprocess_feat, name='GJB2')\n",
    "ryr1_data = get_test_data(RYR1_path, sel_feats, preprocess_feat, name='RYR1')\n",
    "gjb2_VUS_ds = TANDEM_Dataset(gjb2_data['VUS'])\n",
    "gjb2_notVUS_ds = TANDEM_Dataset(gjb2_data['notVUS'])\n",
    "ryr1_VUS_ds = TANDEM_Dataset(ryr1_data['VUS'])\n",
    "ryr1_notVUS_ds = TANDEM_Dataset(ryr1_data['notVUS'])\n",
    "\n",
    "gjb2_VUS_loader = torch.utils.data.DataLoader(gjb2_VUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "gjb2_notVUS_loader = torch.utils.data.DataLoader(gjb2_notVUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "ryr1_VUS_loader = torch.utils.data.DataLoader(ryr1_VUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "ryr1_notVUS_loader = torch.utils.data.DataLoader(ryr1_notVUS_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "\n",
    "from src.train.train import train_model\n",
    "for i in range(5):\n",
    "    writer = SummaryWriter(log_dir=f'logs/{config[\"experiment_name\"]}/fold_{i}')\n",
    "    train_ds = TANDEM_Dataset(folds[i]['train'])\n",
    "    val_ds = TANDEM_Dataset(folds[i]['val'])\n",
    "    test_ds = TANDEM_Dataset(folds[i]['test'])\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=config['train']['batch_size'], shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "    # Estimate the initial bias\n",
    "    pos = len([folds[i]['train'][1]==0])\n",
    "    neg = len([folds[i]['train'][1]==1])\n",
    "    initial_bias = torch.tensor([pos/neg], dtype=torch.float)\n",
    "    torch.manual_seed(config['seed']) # random seed\n",
    "    device = \"cpu\"\n",
    "    device = torch.device(device)\n",
    "    train_model(config, train_loader, val_loader, [test_loader, gjb2_notVUS_loader, ryr1_notVUS_loader],\n",
    "                ['test', 'GJB2', 'RYR1'], writer, output_bias=initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train.run import get_seed, use_all_gpus, get_config, build_model\n",
    "from src.train.modules import build_optimizer\n",
    "import tensorflow as tf\n",
    "n_hidden=6 ; patience=50\n",
    "n_feats = 33\n",
    "input_shape = 33\n",
    "cfg = get_config(input_shape, n_hidden=n_hidden, patience=patience)\n",
    "model = build_model(cfg)\n",
    "\n",
    "optimizer = build_optimizer(cfg)\n",
    "model.compile(optimizer=optimizer, loss=cfg.training.loss, \n",
    "                    metrics=[\n",
    "                        tf.keras.metrics.Accuracy(name='accuracy'),\n",
    "                            tf.keras.metrics.AUC(name='auc'), \n",
    "                            tf.keras.metrics.Precision(name='precision'), \n",
    "                            tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.train.split_data import get_data\n",
    "from src.utils.settings import ROOT_DIR\n",
    "from src.train.run import  get_GJB2, get_RYR1, get_data, train_model, get_seed, use_all_gpus, get_config\n",
    "from prody import LOGGER\n",
    "import os \n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "ryr1 = 'data/RYR1/fReplaceDYN_25Mar19.csv'\n",
    "gjb2 = 'data/GJB2/fReplaceDYN_25Mar18.csv'\n",
    "r20000 = 'data/R20000/fReplaceDYN_25Mar19.csv'\n",
    "\n",
    "\n",
    "ryr1 = 'data/RYR1/oldfReplaceDYNandPfam_25Mar19.csv'\n",
    "gjb2 = 'data/GJB2/oldfReplaceDYNandPfam_25Mar18.csv'\n",
    "r20000 = 'data/R20000/oldfReplaceDYN_withNEWpfam_25Mar25.csv'\n",
    "\n",
    "ryr1 = 'data/RYR1/oldfReplaceDYNandPfam_25Mar19.csv'\n",
    "gjb2 = 'data/GJB2/oldfReplaceDYNandPfam_25Mar18.csv'\n",
    "r20000 = 'data/R20000/oldfReplaceDYN_withNEWpfam_25Mar25.csv'\n",
    "\n",
    "\n",
    "# clstr_path = os.path.join(ROOT_DIR, 'data/c30_clstr_May13_full_rhd.csv')\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/old/c30_clstr_May13.csv')\n",
    "old_feat_names = ['consurf', 'wt_PSIC', 'Delta_PSIC', 'entropy', 'ACNR', 'sasa', 'BLOSUM', 'stiffness-chain', 'loop_percent', 'atomic_1', 'vector_2', 'co_rank', 'atomic_3', 'atomic_5', 'Dcom', 'vector_1', 'rank_2', 'eig_first', 'ranked_MI', 'delta_h_bond_group', 'phobic_percent', 'eig_sec', 'sheet_percent', 'gyradius', 'delta_polarity', 'side_chain_length', 'helix_percent', 'delta_side_chain_length', 'ANM_effectiveness-chain', 'rank_1', 'rmsf_overall', 'delta_charge', 'delta_phobic_percent']\n",
    "new_feat_names = \n",
    "seed = get_seed(seed=150)\n",
    "##################### 1. Set up logging and experiment name #####################\n",
    "NAME_OF_EXPERIMENT = 'test'\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "n_hidden=6 ; patience=50\n",
    "log_dir = os.path.join('logs', NAME_OF_EXPERIMENT, f'improve-{current_time}-seed-{seed}-n_hidden-{n_hidden}')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logging.basicConfig(filename=f'{log_dir}/log.txt', level=logging.ERROR, format='%(message)s')\n",
    "n_feats = 33\n",
    "logging.error(\"Number of features: %d\", n_feats)\n",
    "use_all_gpus()\n",
    "folds, R20000, preprocess_feat, feat_names = get_data(r20000, clstr_path, n_feats=n_feats, new_feat_names)\n",
    "GJB2_knw, GJB2_unk = get_GJB2(gjb2, feat_names, preprocess_feat)\n",
    "RYR1_knw, RYR1_unk = get_RYR1(ryr1, feat_names, preprocess_feat)\n",
    "\n",
    "input_shape = R20000[2].shape[1]\n",
    "cfg = get_config(input_shape, n_hidden=n_hidden, patience=patience)\n",
    "train_model(folds, cfg, log_dir, GJB2_knw, GJB2_unk, RYR1_knw, RYR1_unk, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from modules import np_to_dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "x_train_1 = folds[0]['train']['x']\n",
    "x_test = folds[0]['test']['x']\n",
    "y_test = folds[0]['test']['y']\n",
    "test_ds = np_to_dataset(x_test, y_test, shuffle=False, batch_size=300)\n",
    "\n",
    "df_x_train_1 = pd.DataFrame(x_train_1, columns=feat_names)\n",
    "df_x_test = pd.DataFrame(x_test, columns=feat_names)\n",
    "\n",
    "model_path = './logs/thesis-Optimization/improve-20240706-2033-seed-150/n_hidden_6' #model_fold_1.h5'\n",
    "models = [load_model(os.path.join(model_path, f'model_fold_{i}.h5')) for i in range(1, 6)]\n",
    "\n",
    "# Make prediction\n",
    "y_pred = models[0].predict(x_test)\n",
    "\n",
    "y_test_indicator = np.argmax(y_test, axis=1)\n",
    "y_pred_indicator = np.argmax(y_pred, axis=1)\n",
    "print(f'F1 score: {f1_score(y_test_indicator, y_pred_indicator)}')\n",
    "print(f'Accuracy: {accuracy_score(y_test_indicator, y_pred_indicator)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.train.split_data import get_data\n",
    "from src.utils.settings import ROOT_DIR\n",
    "from src.train.run import  get_GJB2, get_RYR1, get_data, train_model, get_seed, use_all_gpus, get_config\n",
    "import os \n",
    "import logging\n",
    "import datetime\n",
    "import pandas as pd\n",
    "ryr1 = 'data/RYR1/features_withNEWpfam_25Mar26.csv'\n",
    "gjb2 = 'data/GJB2/features_withNEWpfam_25Mar26.csv'\n",
    "r20000 = 'data/R20000/features_withNEWpfam_25Mar26.csv'\n",
    "\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/old/c30_clstr_May13.csv')\n",
    "new_feat_names = ['consurf', 'wtPSIC', 'deltaPSIC', 'entropy', 'ACNR', 'SASA', 'BLOSUM', 'ANM_stiffness_reduced', 'loop_percent', 'AG1', 'GNM_V2_reduced', 'GNM_co_rank_reduced', 'AG3', 'AG5', 'Dcom', 'GNM_V1_reduced', 'GNM_rankV2_reduced', 'GNM_Eigval1_reduced', 'ranked_MI', 'DELTA_Hbond', 'phobic_percent', 'GNM_Eigval2_reduced', 'sheet_percent', 'Rg', 'deltaPolarity', 'Lside', 'helix_percent', 'deltaLside', 'ANM_effectiveness_reduced', 'GNM_rankV1_reduced', 'GNM_rmsf_overall_reduced', 'deltaCharge', 'delta_phobic_percent']\n",
    "seed = get_seed(seed=150)\n",
    "##################### 1. Set up logging and experiment name #####################\n",
    "NAME_OF_EXPERIMENT = 'test'\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "n_hidden=6 ; patience=50\n",
    "log_dir = os.path.join('logs', NAME_OF_EXPERIMENT, f'{current_time}-seed-{seed}-n_hidden-{n_hidden}')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logging.basicConfig(filename=f'{log_dir}/log.txt', level=logging.ERROR, format='%(message)s')\n",
    "n_feats = 33\n",
    "logging.error(\"Number of features: %d\", n_feats)\n",
    "use_all_gpus()\n",
    "folds, R20000, preprocess_feat, feat_names = get_data(r20000, clstr_path, n_feats=n_feats, feat_names=new_feat_names)\n",
    "GJB2_knw, GJB2_unk = get_GJB2(gjb2, feat_names, preprocess_feat)\n",
    "RYR1_knw, RYR1_unk = get_RYR1(ryr1, feat_names, preprocess_feat)\n",
    "\n",
    "input_shape = R20000[2].shape[1]\n",
    "cfg = get_config(input_shape, n_hidden=n_hidden, patience=patience)\n",
    "train_model(folds, cfg, log_dir, GJB2_knw, GJB2_unk, RYR1_knw, RYR1_unk, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.settings import ROOT_DIR\n",
    "from src.train.run import  get_GJB2, get_RYR1, get_data, train_model, get_seed, use_all_gpus, get_config\n",
    "from prody import LOGGER\n",
    "import os \n",
    "import logging\n",
    "import datetime\n",
    "import pandas as pd\n",
    "ryr1 = 'data/RYR1/features_withNEWpfam_25Mar26.csv'\n",
    "gjb2 = 'data/GJB2/features_withNEWpfam_25Mar26.csv'\n",
    "r20000 = 'data/R20000/features_withNEWpfam_25Mar26.csv'\n",
    "\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/old/c30_clstr_May13.csv')\n",
    "new_feat_names = ['GNM_co_rank_reduced', 'ANM_stiffness_reduced', 'GNM_V1_reduced', \n",
    "'wtBJCE', 'GNM_V2_reduced', 'GNM_SEall_reduced', 'GNM_rankV2_reduced', \n",
    "'GNM_rankV1_reduced', 'GNM_SE20_reduced', 'GNM_Eigval2_reduced', \n",
    "'GNM_Eigval5_1_reduced', 'deltaBJCE', 'SASA', 'Dcom', 'loop_percent', 'AG1', 'AG5', 'AG3', 'SSbond', \n",
    "'Hbond', 'DELTA_DSS', 'DELTA_Hbond', 'sheet_percent', 'helix_percent', 'IDRs', \n",
    "'consurf', 'ACNR', 'wtPSIC', 'deltaPSIC', 'entropy', 'BLOSUM', 'ranked_MI', 'deltaPolarity']\n",
    "seed = get_seed(seed=150)\n",
    "##################### 1. Set up logging and experiment name #####################\n",
    "NAME_OF_EXPERIMENT = 'test'\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "n_hidden=6 ; patience=50\n",
    "log_dir = os.path.join('logs', NAME_OF_EXPERIMENT, f'New_ranking_33feats-{current_time}-seed-{seed}-n_hidden-{n_hidden}')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logging.basicConfig(filename=f'{log_dir}/log.txt', level=logging.ERROR, format='%(message)s')\n",
    "n_feats = 33\n",
    "logging.error(\"Number of features: %d\", n_feats)\n",
    "logging.error(\"Feature names: %s\", new_feat_names)\n",
    "use_all_gpus()\n",
    "folds, R20000, preprocess_feat, feat_names = get_data(r20000, clstr_path, n_feats=n_feats, feat_names=new_feat_names)\n",
    "GJB2_knw, GJB2_unk = get_GJB2(gjb2, feat_names, preprocess_feat)\n",
    "RYR1_knw, RYR1_unk = get_RYR1(ryr1, feat_names, preprocess_feat)\n",
    "\n",
    "input_shape = R20000[2].shape[1]\n",
    "cfg = get_config(input_shape, n_hidden=n_hidden, patience=patience, dropout_rate=0.2)\n",
    "train_model(folds, cfg, log_dir, GJB2_knw, GJB2_unk, RYR1_knw, RYR1_unk, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEQ-only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.settings import ROOT_DIR\n",
    "from src.train.run import  get_GJB2, get_RYR1, get_data, train_model, get_seed, use_all_gpus, get_config\n",
    "# from prody import LOGGER\n",
    "import os \n",
    "import logging\n",
    "import datetime\n",
    "import pandas as pd\n",
    "ryr1 = 'data/RYR1/features_withNEWpfam_25Mar26.csv'\n",
    "gjb2 = 'data/GJB2/features_withNEWpfam_25Mar26.csv'\n",
    "r20000 = 'data/R20000/features_withNEWpfam_25Mar26.csv'\n",
    "\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/old/c30_clstr_May13.csv')\n",
    "new_feat_names = ['GNM_co_rank_reduced', 'ANM_stiffness_reduced', 'GNM_V1_reduced', \n",
    "'wtBJCE', 'GNM_V2_reduced', 'GNM_SEall_reduced', 'GNM_rankV2_reduced', \n",
    "'GNM_rankV1_reduced', 'GNM_SE20_reduced', 'GNM_Eigval2_reduced', \n",
    "'GNM_Eigval5_1_reduced', 'deltaBJCE', 'SASA', 'Dcom', 'loop_percent', 'AG1', 'AG5', 'AG3', 'SSbond', \n",
    "'Hbond', 'DELTA_DSS', 'DELTA_Hbond', 'sheet_percent', 'helix_percent', 'IDRs', \n",
    "'consurf', 'ACNR', 'wtPSIC', 'deltaPSIC', 'entropy', 'BLOSUM', 'ranked_MI', 'deltaPolarity']\n",
    "fns = ['BLOSUM', 'phobic_percent', 'delta_phobic_percent', 'charge', 'deltaCharge', 'charge_pH7', 'DELTA_charge_pH7', \n",
    "       'polarity', 'deltaPolarity', 'entropy', 'ranked_MI', 'consurf', 'wtPSIC', 'deltaPSIC', 'ACNR']\n",
    "fns = fns+['SASA', 'GNM_co_rank_reduced', 'ANM_stiffness_reduced', 'Dcom', 'loop_percent', 'AG1', 'AG5', 'GNM_V1_reduced', 'AG3', 'wtBJCE', 'DELTA_Hbond', 'GNM_V2_reduced', 'sheet_percent', 'SSbond', 'DELTA_DSS', 'Hbond', 'GNM_SE20_reduced', 'deltaBJCE']\n",
    "seed = get_seed(seed=150)\n",
    "##################### 1. Set up logging and experiment name #####################\n",
    "NAME_OF_EXPERIMENT = 'test'\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "n_hidden=6 ; patience=50\n",
    "log_dir = os.path.join('logs', NAME_OF_EXPERIMENT, f'RemoveP00451-{current_time}-seed-{seed}-n_hidden-{n_hidden}')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logging.basicConfig(filename=f'{log_dir}/log.txt', level=logging.ERROR, format='%(message)s')\n",
    "n_feats = 33\n",
    "logging.error(\"Number of features: %d\", n_feats)\n",
    "# logging.error(\"Feature names: %s\", fns)\n",
    "use_all_gpus()\n",
    "folds, R20000, preprocess_feat, feat_names = get_data(r20000, clstr_path, n_feats=n_feats, feat_names=fns)\n",
    "GJB2_knw, GJB2_unk = get_GJB2(gjb2, feat_names, preprocess_feat) \n",
    "RYR1_knw, RYR1_unk = get_RYR1(ryr1, feat_names, preprocess_feat)\n",
    "input_shape = R20000[2].shape[1]\n",
    "cfg = get_config(input_shape, n_hidden=n_hidden, patience=patience)#, dropout_rate=0.2)\n",
    "train_model(folds, cfg, log_dir, GJB2_knw, GJB2_unk, RYR1_knw, RYR1_unk, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.settings import ROOT_DIR\n",
    "from src.train.run import  get_GJB2, get_RYR1, get_data, train_model, get_seed, use_all_gpus, get_config\n",
    "# from prody import LOGGER\n",
    "import os \n",
    "import logging\n",
    "import datetime\n",
    "import pandas as pd\n",
    "ryr1 = 'data/RYR1/features_withNEWpfam_25Mar26.csv'\n",
    "gjb2 = 'data/GJB2/features_withNEWpfam_25Mar26.csv'\n",
    "r20000 = 'data/R20000/features_withNEWpfam_25Mar26.csv'\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/old/c30_clstr_May13.csv')\n",
    "\n",
    "fns = ['BLOSUM', 'phobic_percent', 'delta_phobic_percent', 'charge', 'deltaCharge', 'charge_pH7', 'DELTA_charge_pH7', \n",
    "       'polarity', 'deltaPolarity', 'entropy', 'ranked_MI', 'consurf', 'wtPSIC', 'deltaPSIC', 'ACNR']\n",
    "fns = fns+['SASA', 'GNM_co_rank_reduced', 'ANM_stiffness_reduced', 'Dcom', 'loop_percent', 'AG1', 'AG5', 'GNM_V1_reduced', 'AG3', 'wtBJCE', 'DELTA_Hbond', 'GNM_V2_reduced', 'sheet_percent', 'SSbond', 'DELTA_DSS', 'Hbond', 'GNM_SE20_reduced', 'deltaBJCE']\n",
    "folds, R20000, preprocess_feat, feat_names = get_data(r20000, clstr_path, feat_names=fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r20000)\n",
    "df[df['SAV_coords'].str.contains('P04637')].labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class rDNN(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    This class defines the rDNN model in TensorFlow, equivalent to the PyTorch version.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape=33, n_hidden=6, output_shape=2, dropout=0.2, output_bias=None):\n",
    "        super(rDNN, self).__init__()\n",
    "\n",
    "        hidden_shape = 33\n",
    "        hidden_last_shape = 10\n",
    "\n",
    "        self.hidden_layers = []\n",
    "        self.hidden_layers.append(tf.keras.layers.Dense(hidden_shape, input_shape=(input_shape,)))\n",
    "        \n",
    "        for _ in range(n_hidden - 1):\n",
    "            self.hidden_layers.append(tf.keras.layers.Dense(hidden_shape))\n",
    "        \n",
    "        self.hidden_layers.append(tf.keras.layers.Dense(hidden_last_shape))\n",
    "\n",
    "        # Output layer\n",
    "        if output_bias is not None:\n",
    "            output_bias_initializer = tf.keras.initializers.Constant(output_bias)\n",
    "        else:\n",
    "            output_bias_initializer = 'zeros'\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Dense(output_shape, bias_initializer=output_bias_initializer)\n",
    "        \n",
    "        self.gelu = tf.keras.activations.gelu\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "            x = self.gelu(x)\n",
    "            x = self.dropout(x, training=training)\n",
    "        x = self.output_layer(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "model = rDNN(input_shape=33, n_hidden=5, output_shape=2, dropout=0.2)\n",
    "\n",
    "x = tf.random.normal((1, 33))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.settings import ROOT_DIR\n",
    "from src.train.run import  get_GJB2, get_RYR1, get_data, train_model, get_seed, use_all_gpus, get_config\n",
    "import os \n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "r20000 = 'data/R20000/feat_rename_and_recal_otherfeatures_features_24Sep29.csv'\n",
    "gjb2 = 'data/GJB2/features_25Apr01.csv'\n",
    "ryr1 = 'data/RYR1/feat_rename_and_recal_otherfeatures_features_24May20.csv'\n",
    "\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/old/c30_clstr_May13.csv')\n",
    "fns = [\n",
    "    \"consurf\", \"wtPSIC\", \"deltaPSIC\", \"entropy\", \"ACNR\", \"SASA\", \"BLOSUM\", \"ANM_stiffness_chain\",\n",
    "    \"loop_percent\", \"AG1\", \"GNM_V2_full\", \"GNM_co_rank_full\", \"AG3\", \"AG5\", \"Dcom\", \"GNM_V1_full\",\n",
    "    \"GNM_rankV2_full\", \"GNM_Eigval1_full\", \"ranked_MI\", \"DELTA_Hbond\", \"phobic_percent\", \"GNM_Eigval2_full\",\n",
    "    \"sheet_percent\", \"Rg\", \"deltaPolarity\", \"Lside\", \"helix_percent\", \"deltaLside\", \"ANM_effectiveness_chain\",\n",
    "    \"GNM_rankV1_full\", \"GNM_rmsf_overall_full\", \"deltaCharge\", \"delta_phobic_percent\"]\n",
    "seed = get_seed(seed=150)\n",
    "##################### 1. Set up logging and experiment name #####################\n",
    "NAME_OF_EXPERIMENT = 'test'\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "n_hidden=6 ; patience=50\n",
    "log_dir = os.path.join('logs', NAME_OF_EXPERIMENT, f'testxongxoa')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logging.basicConfig(filename=f'{log_dir}/log.txt', level=logging.ERROR, format='%(message)s')\n",
    "n_feats = 33\n",
    "logging.error(\"Number of features: %d\", n_feats)\n",
    "use_all_gpus()\n",
    "folds, R20000, preprocess_feat, feat_names = get_data(r20000, clstr_path, n_feats=n_feats, feat_names=fns)\n",
    "GJB2_knw, GJB2_unk = get_GJB2(gjb2, feat_names, preprocess_feat) \n",
    "RYR1_knw, RYR1_unk = get_RYR1(ryr1, feat_names, preprocess_feat)\n",
    "\n",
    "input_shape = R20000[2].shape[1]\n",
    "cfg = get_config(input_shape, n_hidden=n_hidden, patience=patience)#, dropout_rate=0.2)\n",
    "train_model(folds, cfg, log_dir, GJB2_knw, GJB2_unk, RYR1_knw, RYR1_unk, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.settings import ROOT_DIR\n",
    "from src.train.run import  get_GJB2, get_RYR1, get_data, train_model, get_seed, use_all_gpus, get_config\n",
    "import os \n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "r20000 = 'data/R20000/feat_rename_and_recal_otherfeatures_features_24Sep29.csv'\n",
    "gjb2 = 'data/GJB2/features_25Apr01.csv'\n",
    "ryr1 = 'data/RYR1/feat_rename_and_recal_otherfeatures_features_24May20.csv'\n",
    "\n",
    "\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/old/c30_clstr_May13.csv')\n",
    "fns = [\n",
    "    \"consurf\", \"wtPSIC\", \"deltaPSIC\", \"entropy\", \"ACNR\", \"SASA\", \"BLOSUM\", \"ANM_stiffness_chain\",\n",
    "    \"loop_percent\", \"AG1\", \"GNM_V2_full\", \"GNM_co_rank_full\", \"AG3\", \"AG5\", \"Dcom\", \"GNM_V1_full\",\n",
    "    \"GNM_rankV2_full\", \"GNM_Eigval1_full\", \"ranked_MI\", \"DELTA_Hbond\", \"phobic_percent\", \"GNM_Eigval2_full\",\n",
    "    \"sheet_percent\", \"Rg\", \"deltaPolarity\", \"Lside\", \"helix_percent\", \"deltaLside\", \"ANM_effectiveness_chain\",\n",
    "    \"GNM_rankV1_full\", \"GNM_rmsf_overall_full\", \"deltaCharge\", \"delta_phobic_percent\"]\n",
    "seed = get_seed(seed=150)\n",
    "##################### 1. Set up logging and experiment name #####################\n",
    "NAME_OF_EXPERIMENT = 'test'\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "n_hidden=6 ; patience=50\n",
    "log_dir = os.path.join('logs', NAME_OF_EXPERIMENT, f'recal_{current_time}_differentDroprates')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logging.basicConfig(filename=f'{log_dir}/log.txt', level=logging.ERROR, format='%(message)s')\n",
    "logging.error(f\"r20000: {r20000}\")\n",
    "logging.error(f\"gjb2: {gjb2}\")\n",
    "logging.error(f\"ryr1: {ryr1}\")\n",
    "logging.error(f\"clstr_path: {clstr_path}\")\n",
    "logging.error(f\"fns: {fns}\")\n",
    "logging.error(f\"seed: {seed}\")\n",
    "logging.error(\"Description: Recalculate all features and use the new features to train the model\")\n",
    "logging.error(\"Experiment with different drop rates\")\n",
    "logging.error(\"*\"*50)\n",
    "n_feats = 33\n",
    "logging.error(\"Number of features: %d\", n_feats)\n",
    "use_all_gpus()\n",
    "folds, R20000, preprocess_feat, feat_names = get_data(r20000, clstr_path, n_feats=n_feats, feat_names=fns)\n",
    "GJB2_knw, GJB2_unk = get_GJB2(gjb2, feat_names, preprocess_feat) \n",
    "RYR1_knw, RYR1_unk = get_RYR1(ryr1, feat_names, preprocess_feat)\n",
    "input_shape = R20000[2].shape[1]\n",
    "\n",
    "drop_rates = [0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "for drop_rate in drop_rates:\n",
    "    cfg = get_config(input_shape, n_hidden=n_hidden, patience=patience, dropout_rate=drop_rate)\n",
    "    fold_dir = os.path.join(log_dir, f'dropout_rate-{drop_rate}')\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "    train_model(folds, cfg, fold_dir, GJB2_knw, GJB2_unk, RYR1_knw, RYR1_unk, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.settings import ROOT_DIR\n",
    "from src.train.run import  get_GJB2, get_RYR1, get_data, train_model, get_seed, use_all_gpus, get_config\n",
    "import os \n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "r20000 = 'data/R20000/feat_rename_and_recal_otherfeatures_features_24Sep29.csv'\n",
    "gjb2 = 'data/GJB2/features_25Apr01.csv'\n",
    "ryr1 = 'data/RYR1/feat_rename_and_recal_otherfeatures_features_24May20.csv'\n",
    "\n",
    "\n",
    "clstr_path = os.path.join(ROOT_DIR, 'data/old/c30_clstr_May13.csv')\n",
    "fns = [\n",
    "    \"consurf\", \"wtPSIC\", \"deltaPSIC\", \"entropy\", \"ACNR\", \"SASA\", \"BLOSUM\", \"ANM_stiffness_chain\",\n",
    "    \"loop_percent\", \"AG1\", \"GNM_V2_full\", \"GNM_co_rank_full\", \"AG3\", \"AG5\", \"Dcom\", \"GNM_V1_full\",\n",
    "    \"GNM_rankV2_full\", \"GNM_Eigval1_full\", \"ranked_MI\", \"DELTA_Hbond\", \"phobic_percent\", \"GNM_Eigval2_full\",\n",
    "    \"sheet_percent\", \"Rg\", \"deltaPolarity\", \"Lside\", \"helix_percent\", \"deltaLside\",\n",
    "    \"GNM_rankV1_full\", \"GNM_rmsf_overall_full\", \"deltaCharge\", 'wtBJCE', 'deltaBJCE']\n",
    "seed = get_seed(seed=150)\n",
    "##################### 1. Set up logging and experiment name #####################\n",
    "NAME_OF_EXPERIMENT = 'test'\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "n_hidden=6 ; patience=50\n",
    "log_dir = os.path.join('logs', NAME_OF_EXPERIMENT, f'recal_{current_time}_replace_EffanddeltaPhob_withBJCE')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logging.basicConfig(filename=f'{log_dir}/log.txt', level=logging.ERROR, format='%(message)s')\n",
    "logging.error(f\"r20000: {r20000}\")\n",
    "logging.error(f\"gjb2: {gjb2}\")\n",
    "logging.error(f\"ryr1: {ryr1}\")\n",
    "logging.error(f\"clstr_path: {clstr_path}\")\n",
    "logging.error(f\"seed: {seed}\")\n",
    "logging.error(\"Description: Recalculate all features and use the new features to train the model\")\n",
    "logging.error(\"Description: Replace Effectiveness and delta_phobic_percent with wtBJCE and deltaBJCE\")\n",
    "# logging.error(\"Experiment with different drop rates\")\n",
    "logging.error(\"*\"*50)\n",
    "n_feats = 33\n",
    "logging.error(\"Number of features: %d\", n_feats)\n",
    "use_all_gpus()\n",
    "folds, R20000, preprocess_feat, feat_names = get_data(r20000, clstr_path, n_feats=n_feats, feat_names=fns)\n",
    "GJB2_knw, GJB2_unk = get_GJB2(gjb2, feat_names, preprocess_feat) \n",
    "RYR1_knw, RYR1_unk = get_RYR1(ryr1, feat_names, preprocess_feat)\n",
    "input_shape = R20000[2].shape[1]\n",
    "cfg = get_config(input_shape, n_hidden=n_hidden, patience=patience)\n",
    "train_model(folds, cfg, log_dir, GJB2_knw, GJB2_unk, RYR1_knw, RYR1_unk, seed=seed)\n",
    "\n",
    "# drop_rates = [0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "# for drop_rate in drop_rates:\n",
    "#     cfg = get_config(input_shape, n_hidden=n_hidden, patience=patience, dropout_rate=drop_rate)\n",
    "#     fold_dir = os.path.join(log_dir, f'dropout_rate-{drop_rate}')\n",
    "#     os.makedirs(fold_dir, exist_ok=True)\n",
    "#     train_model(folds, cfg, fold_dir, GJB2_knw, GJB2_unk, RYR1_knw, RYR1_unk, seed=seed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
