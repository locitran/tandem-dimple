**************************************************
Feature selection: all 33 features from Rhapsody
Feature set: ['ANM_MSF-chain', 'ANM_MSF-reduced', 'ANM_MSF-sliced', 'ANM_effectiveness-chain', 'ANM_effectiveness-reduced', 'ANM_effectiveness-sliced', 'ANM_sensitivity-chain', 'ANM_sensitivity-reduced', 'ANM_sensitivity-sliced', 'BLOSUM', 'Delta_PSIC', 'Delta_SASA', 'EVmut-DeltaE_epist', 'EVmut-DeltaE_indep', 'EVmut-mut_aa_freq', 'EVmut-wt_aa_cons', 'GNM_MSF-chain', 'GNM_MSF-reduced', 'GNM_MSF-sliced', 'GNM_effectiveness-chain', 'GNM_effectiveness-reduced', 'GNM_effectiveness-sliced', 'GNM_sensitivity-chain', 'GNM_sensitivity-reduced', 'GNM_sensitivity-sliced', 'SASA', 'SASA_in_complex', 'entropy', 'ranked_MI', 'stiffness-chain', 'stiffness-reduced', 'stiffness-sliced', 'wt_PSIC']
**************************************************
Feature files
R20000: /mnt/nas_1/YangLab/loci/tandem/data/R20000/rhd_final_features.csv
GJB2: /mnt/nas_1/YangLab/loci/tandem/data/GJB2/rhd_final_features.csv
RYR1: /mnt/nas_1/YangLab/loci/tandem/data/RYR1/rhd_final_features.csv
Cluster path: /mnt/nas_1/YangLab/loci/tandem/data/R20000/c30_clstr_May13.csv
Description: RHAPSODY feature set for R20000, GJB2, and RYR1
Training DNN with 33 features ranked by ttest
**************************************************
Num GPUs Available: 0
GPUs: []
**************************************************
Missing values in the dataframe:
ANM_MSF-reduced: 		 41
ANM_MSF-sliced: 		 41
ANM_effectiveness-reduced: 		 41
ANM_effectiveness-sliced: 		 41
ANM_sensitivity-reduced: 		 41
ANM_sensitivity-sliced: 		 41
Delta_PSIC: 		 1
Delta_SASA: 		 170
EVmut-DeltaE_epist: 		 6717
EVmut-DeltaE_indep: 		 6717
EVmut-mut_aa_freq: 		 6717
EVmut-wt_aa_cons: 		 6717
GNM_MSF-reduced: 		 41
GNM_MSF-sliced: 		 41
GNM_effectiveness-reduced: 		 41
GNM_effectiveness-sliced: 		 41
GNM_sensitivity-reduced: 		 41
GNM_sensitivity-sliced: 		 41
SASA: 		 170
SASA_in_complex: 		 167
entropy: 		 3769
ranked_MI: 		 3769
stiffness-reduced: 		 41
stiffness-sliced: 		 41
Assigning the mean value of feature to the missing values
Assigning mean value to ANM_MSF-reduced: 24.67
Assigning mean value to ANM_MSF-sliced: 26.93
Assigning mean value to ANM_effectiveness-reduced: 0.27
Assigning mean value to ANM_effectiveness-sliced: 0.34
Assigning mean value to ANM_sensitivity-reduced: 0.24
Assigning mean value to ANM_sensitivity-sliced: 0.30
Assigning mean value to Delta_PSIC: 1.83
Assigning mean value to Delta_SASA: 4.52
Assigning mean value to EVmut-DeltaE_epist: -5.53
Assigning mean value to EVmut-DeltaE_indep: -3.91
Assigning mean value to EVmut-mut_aa_freq: 0.04
Assigning mean value to EVmut-wt_aa_cons: 0.53
Assigning mean value to GNM_MSF-reduced: 0.10
Assigning mean value to GNM_MSF-sliced: 0.11
Assigning mean value to GNM_effectiveness-reduced: 0.03
Assigning mean value to GNM_effectiveness-sliced: 0.06
Assigning mean value to GNM_sensitivity-reduced: 0.03
Assigning mean value to GNM_sensitivity-sliced: 0.06
Assigning mean value to SASA: 44.81
Assigning mean value to SASA_in_complex: 40.29
Assigning mean value to entropy: 1.65
Assigning mean value to ranked_MI: 0.48
Assigning mean value to stiffness-reduced: 16.29
Assigning mean value to stiffness-sliced: 16.33
**************************************************
1 members: 1428 clusters
2 members: 226 clusters
3 members: 57 clusters
4 members: 24 clusters
5 members: 18 clusters
7 members: 8 clusters
6 members: 6 clusters
9 members: 3 clusters
8 members: 2 clusters
36 members: 1 clusters
10 members: 1 clusters
No. UniProtID: 2423, No. SAVs: 20361, and No. clusters: 1774
No. pathogenic SAVs: 13626 and benign SAVs: 6735
**************************************************
> Deleting cluster P29033 from data_sorted
No. clusters: 1773
No. SAVs after deleting P29033: 20295
**************************************************
> Adding cluster P29033 to the test set
Test set percent = 10.03% is larger than 10%: Breaking the loop
No. adding to test set: 34
Cluster IDs added to the test set: [67, 5, 11, 17, 23, 29, 35, 41, 47, 53, 59, 65, 72, 78, 84, 90, 96, 102, 108, 114, 120, 126, 132, 138, 144, 150, 156, 162, 168, 174, 180, 186, 192, 198]
Member IDs added to the test set: ['P29033', 'P07101', 'Q8IWU9', 'P00439', 'Q9UHC9', 'O15118', 'P22304', 'P30613', 'P14618', 'P35520', 'P11509', 'Q16696', 'P05181', 'P20813', 'P11712', 'P10632', 'P33261', 'P00966', 'P11413', 'Q93099', 'P15848', 'P54802', 'P60484', 'Q06124', 'P09619', 'P16234', 'P10721', 'P07333', 'P78504', 'Q9NR61', 'P52701', 'Q15831', 'P08559', 'P06400', 'P00156', 'P78527', 'Q14353', 'Q13224', 'Q12879', 'Q9H251', 'P51648', 'P30838', 'P18074', 'O94759', 'Q8TD43', 'P00813', 'O14733', 'P36507', 'P45985', 'Q02750', 'Q96L73', 'O43240', 'P06870', 'P07288', 'P20151', 'O60259', 'Q9Y5K2', 'P23946', 'P07477', 'Q92876', 'P46597', 'P03891']
> Delete test indices from data_sorted
No. clusters after deleting test indices: 1740
No. SAVs after deleting test indices: 18596
**************************************************
> Adding cluster Q16874 P55735 P57740 Q12769 Q9BW27 to the training set
Q16874 SAVs: 71
Q16874 SAV coords: P55735 172 S L
Q16874 SAV labels: 0
**************************************************
> Adding cluster P04745 to the validation set
Fold 0: 
         Train: n_SAVs = 14651, % SAVs = 71.96%, n_pathogenic = 8967, n_benign = 5684, ratio = 1.58:1, n_clusters = 1652, n_members = 2189
         Val: n_SAVs = 3667, % SAVs = 18.01%, n_pathogenic = 3010, n_benign = 657, ratio = 4.58:1, n_clusters = 88, n_members = 168
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 1: 
         Train: n_SAVs = 14652, % SAVs = 71.96%, n_pathogenic = 9287, n_benign = 5365, ratio = 1.73:1, n_clusters = 1541, n_members = 2039
         Val: n_SAVs = 3666, % SAVs = 18.01%, n_pathogenic = 2690, n_benign = 976, ratio = 2.76:1, n_clusters = 199, n_members = 318
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 2: 
         Train: n_SAVs = 14653, % SAVs = 71.97%, n_pathogenic = 10113, n_benign = 4540, ratio = 2.23:1, n_clusters = 1403, n_members = 1861
         Val: n_SAVs = 3665, % SAVs = 18.00%, n_pathogenic = 1864, n_benign = 1801, ratio = 1.03:1, n_clusters = 337, n_members = 496
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 3: 
         Train: n_SAVs = 14653, % SAVs = 71.97%, n_pathogenic = 9852, n_benign = 4801, ratio = 2.05:1, n_clusters = 1255, n_members = 1733
         Val: n_SAVs = 3665, % SAVs = 18.00%, n_pathogenic = 2125, n_benign = 1540, ratio = 1.38:1, n_clusters = 485, n_members = 624
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 4: 
         Train: n_SAVs = 14663, % SAVs = 72.02%, n_pathogenic = 9689, n_benign = 4974, ratio = 1.95:1, n_clusters = 1109, n_members = 1606
         Val: n_SAVs = 3655, % SAVs = 17.95%, n_pathogenic = 2288, n_benign = 1367, ratio = 1.67:1, n_clusters = 631, n_members = 751
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
**************************************************
Missing values in the dataframe:
EVmut-DeltaE_indep: 		 4
EVmut-DeltaE_epist: 		 4
EVmut-wt_aa_cons: 		 4
entropy: 		 6
EVmut-mut_aa_freq: 		 4
ranked_MI: 		 6
labels: 		 83
No. Unknown SAVs 25 (benign), 22 (pathogenic), and 83 (NaN)
**************************************************
Missing values in the dataframe:
ranked_MI: 		 52
EVmut-mut_aa_freq: 		 105
EVmut-DeltaE_epist: 		 105
EVmut-wt_aa_cons: 		 105
EVmut-DeltaE_indep: 		 105
entropy: 		 52
labels: 		 30
No. Unknown SAVs 45 (benign), 45 (pathogenic), and 30 (NaN)
Parameter Grid: 
{'n_hidden': [5, 6, 8, 10, 12]}
seed = 17
Input Layer: 33
Model Configuration: 
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Layer   | Activation | Batch Norm | Dropout Rate |  Initializer   | L1 |   L2   | N Neurons |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Input   |     -      |     -      |     0.0      |       -        | -  |   -    |     33    |
| hidden_00 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_01 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_02 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_03 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_04 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     10    |
|   Output  |  softmax   |     -      |      -       |       -        | -  |   -    |     2     |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
Training Configuration: 
+-----------+------------+----------+--------------------------+---------------------+
|  Training | Batch Size | N Epochs |           Loss           |       Metrics       |
+-----------+------------+----------+--------------------------+---------------------+
|  Training |    300     |   300    | categorical_crossentropy | ['accuracy', 'AUC'] |
| Optimizer |   5e-05    |  Nadam   |            -             |          -          |
+-----------+------------+----------+--------------------------+---------------------+
Number of parameters: 4850
Fold 1 - val_loss: 0.51, val_accuracy: 76.9%, val_auc: 0.84, val_precision: 0.77, val_recall: 0.77, test_loss: 0.45, test_accuracy: 81.1%, test_auc: 0.88, test_precision: 0.81, test_recall: 0.81, RYR1_loss: 0.55, RYR1_accuracy: 76.7%, RYR1_auc: 0.82, RYR1_precision: 0.77, RYR1_recall: 0.77, GJB2_loss: 0.34, GJB2_accuracy: 93.6%, GJB2_auc: 0.94, GJB2_precision: 0.94, GJB2_recall: 0.94
Fold 2 - val_loss: 0.47, val_accuracy: 79.3%, val_auc: 0.87, val_precision: 0.79, val_recall: 0.79, test_loss: 0.43, test_accuracy: 83.3%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.57, RYR1_accuracy: 71.1%, RYR1_auc: 0.79, RYR1_precision: 0.71, RYR1_recall: 0.71, GJB2_loss: 0.41, GJB2_accuracy: 87.2%, GJB2_auc: 0.92, GJB2_precision: 0.87, GJB2_recall: 0.87
Fold 3 - val_loss: 0.53, val_accuracy: 75.6%, val_auc: 0.83, val_precision: 0.76, val_recall: 0.76, test_loss: 0.43, test_accuracy: 82.4%, test_auc: 0.89, test_precision: 0.82, test_recall: 0.82, RYR1_loss: 0.59, RYR1_accuracy: 75.6%, RYR1_auc: 0.77, RYR1_precision: 0.76, RYR1_recall: 0.76, GJB2_loss: 0.39, GJB2_accuracy: 80.9%, GJB2_auc: 0.92, GJB2_precision: 0.81, GJB2_recall: 0.81
Fold 4 - val_loss: 0.53, val_accuracy: 75.6%, val_auc: 0.83, val_precision: 0.76, val_recall: 0.76, test_loss: 0.42, test_accuracy: 82.6%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.58, RYR1_accuracy: 73.3%, RYR1_auc: 0.78, RYR1_precision: 0.73, RYR1_recall: 0.73, GJB2_loss: 0.39, GJB2_accuracy: 83.0%, GJB2_auc: 0.92, GJB2_precision: 0.83, GJB2_recall: 0.83
Fold 5 - val_loss: 0.51, val_accuracy: 75.8%, val_auc: 0.84, val_precision: 0.76, val_recall: 0.76, test_loss: 0.44, test_accuracy: 83.2%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.58, RYR1_accuracy: 71.1%, RYR1_auc: 0.78, RYR1_precision: 0.71, RYR1_recall: 0.71, GJB2_loss: 0.38, GJB2_accuracy: 85.1%, GJB2_auc: 0.93, GJB2_precision: 0.85, GJB2_recall: 0.85
-----------------------------------------------------------------
Vali - loss: 0.51±0.01, accuracy: 76.7±0.7%, auc: 0.84±0.01
Test - loss: 0.43±0.01, accuracy: 82.5±0.4%, auc: 0.89±0.00
GJB2 - loss: 0.38±0.01, accuracy: 86.0±2.2%, auc: 0.93±0.00
RYR1 - loss: 0.57±0.01, accuracy: 73.6±1.1%, auc: 0.79±0.01
-----------------------------------------------------------------
Input Layer: 33
Model Configuration: 
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Layer   | Activation | Batch Norm | Dropout Rate |  Initializer   | L1 |   L2   | N Neurons |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Input   |     -      |     -      |     0.0      |       -        | -  |   -    |     33    |
| hidden_00 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_01 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_02 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_03 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_04 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_05 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     10    |
|   Output  |  softmax   |     -      |      -       |       -        | -  |   -    |     2     |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
Training Configuration: 
+-----------+------------+----------+--------------------------+---------------------+
|  Training | Batch Size | N Epochs |           Loss           |       Metrics       |
+-----------+------------+----------+--------------------------+---------------------+
|  Training |    300     |   300    | categorical_crossentropy | ['accuracy', 'AUC'] |
| Optimizer |   5e-05    |  Nadam   |            -             |          -          |
+-----------+------------+----------+--------------------------+---------------------+
Number of parameters: 5972
Fold 1 - val_loss: 0.52, val_accuracy: 76.2%, val_auc: 0.84, val_precision: 0.76, val_recall: 0.76, test_loss: 0.44, test_accuracy: 81.6%, test_auc: 0.89, test_precision: 0.82, test_recall: 0.82, RYR1_loss: 0.56, RYR1_accuracy: 74.4%, RYR1_auc: 0.81, RYR1_precision: 0.74, RYR1_recall: 0.74, GJB2_loss: 0.35, GJB2_accuracy: 91.5%, GJB2_auc: 0.94, GJB2_precision: 0.91, GJB2_recall: 0.91
Fold 2 - val_loss: 0.49, val_accuracy: 78.3%, val_auc: 0.86, val_precision: 0.78, val_recall: 0.78, test_loss: 0.46, test_accuracy: 83.2%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.57, RYR1_accuracy: 71.1%, RYR1_auc: 0.79, RYR1_precision: 0.71, RYR1_recall: 0.71, GJB2_loss: 0.42, GJB2_accuracy: 89.4%, GJB2_auc: 0.92, GJB2_precision: 0.89, GJB2_recall: 0.89
Fold 3 - val_loss: 0.54, val_accuracy: 75.4%, val_auc: 0.82, val_precision: 0.75, val_recall: 0.75, test_loss: 0.46, test_accuracy: 82.8%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.60, RYR1_accuracy: 68.9%, RYR1_auc: 0.77, RYR1_precision: 0.69, RYR1_recall: 0.69, GJB2_loss: 0.39, GJB2_accuracy: 87.2%, GJB2_auc: 0.93, GJB2_precision: 0.87, GJB2_recall: 0.87
Fold 4 - val_loss: 0.54, val_accuracy: 75.3%, val_auc: 0.83, val_precision: 0.75, val_recall: 0.75, test_loss: 0.44, test_accuracy: 83.0%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.58, RYR1_accuracy: 72.2%, RYR1_auc: 0.78, RYR1_precision: 0.72, RYR1_recall: 0.72, GJB2_loss: 0.39, GJB2_accuracy: 85.1%, GJB2_auc: 0.92, GJB2_precision: 0.85, GJB2_recall: 0.85
Fold 5 - val_loss: 0.52, val_accuracy: 76.4%, val_auc: 0.84, val_precision: 0.76, val_recall: 0.76, test_loss: 0.46, test_accuracy: 83.3%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.59, RYR1_accuracy: 70.0%, RYR1_auc: 0.78, RYR1_precision: 0.70, RYR1_recall: 0.70, GJB2_loss: 0.39, GJB2_accuracy: 87.2%, GJB2_auc: 0.93, GJB2_precision: 0.87, GJB2_recall: 0.87
-----------------------------------------------------------------
Vali - loss: 0.52±0.01, accuracy: 76.3±0.5%, auc: 0.84±0.01
Test - loss: 0.45±0.01, accuracy: 82.8±0.3%, auc: 0.90±0.00
GJB2 - loss: 0.39±0.01, accuracy: 88.1±1.1%, auc: 0.93±0.00
RYR1 - loss: 0.58±0.01, accuracy: 71.3±1.0%, auc: 0.79±0.01
-----------------------------------------------------------------
Input Layer: 33
Model Configuration: 
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Layer   | Activation | Batch Norm | Dropout Rate |  Initializer   | L1 |   L2   | N Neurons |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Input   |     -      |     -      |     0.0      |       -        | -  |   -    |     33    |
| hidden_00 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_01 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_02 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_03 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_04 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_05 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_06 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_07 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     10    |
|   Output  |  softmax   |     -      |      -       |       -        | -  |   -    |     2     |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
Training Configuration: 
+-----------+------------+----------+--------------------------+---------------------+
|  Training | Batch Size | N Epochs |           Loss           |       Metrics       |
+-----------+------------+----------+--------------------------+---------------------+
|  Training |    300     |   300    | categorical_crossentropy | ['accuracy', 'AUC'] |
| Optimizer |   5e-05    |  Nadam   |            -             |          -          |
+-----------+------------+----------+--------------------------+---------------------+
Number of parameters: 8216
Fold 1 - val_loss: 0.53, val_accuracy: 75.4%, val_auc: 0.83, val_precision: 0.75, val_recall: 0.75, test_loss: 0.44, test_accuracy: 81.5%, test_auc: 0.89, test_precision: 0.82, test_recall: 0.82, RYR1_loss: 0.56, RYR1_accuracy: 76.7%, RYR1_auc: 0.81, RYR1_precision: 0.77, RYR1_recall: 0.77, GJB2_loss: 0.36, GJB2_accuracy: 89.4%, GJB2_auc: 0.94, GJB2_precision: 0.89, GJB2_recall: 0.89
Fold 2 - val_loss: 0.50, val_accuracy: 78.3%, val_auc: 0.86, val_precision: 0.78, val_recall: 0.78, test_loss: 0.43, test_accuracy: 83.5%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.58, RYR1_accuracy: 70.0%, RYR1_auc: 0.79, RYR1_precision: 0.70, RYR1_recall: 0.70, GJB2_loss: 0.42, GJB2_accuracy: 87.2%, GJB2_auc: 0.92, GJB2_precision: 0.87, GJB2_recall: 0.87
Fold 3 - val_loss: 0.55, val_accuracy: 75.1%, val_auc: 0.82, val_precision: 0.75, val_recall: 0.75, test_loss: 0.43, test_accuracy: 82.6%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.60, RYR1_accuracy: 67.8%, RYR1_auc: 0.76, RYR1_precision: 0.68, RYR1_recall: 0.68, GJB2_loss: 0.40, GJB2_accuracy: 83.0%, GJB2_auc: 0.93, GJB2_precision: 0.83, GJB2_recall: 0.83
Fold 4 - val_loss: 0.53, val_accuracy: 75.7%, val_auc: 0.83, val_precision: 0.76, val_recall: 0.76, test_loss: 0.43, test_accuracy: 82.5%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.59, RYR1_accuracy: 71.1%, RYR1_auc: 0.77, RYR1_precision: 0.71, RYR1_recall: 0.71, GJB2_loss: 0.42, GJB2_accuracy: 78.7%, GJB2_auc: 0.90, GJB2_precision: 0.79, GJB2_recall: 0.79
Fold 5 - val_loss: 0.52, val_accuracy: 76.1%, val_auc: 0.84, val_precision: 0.76, val_recall: 0.76, test_loss: 0.43, test_accuracy: 83.4%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.60, RYR1_accuracy: 71.1%, RYR1_auc: 0.78, RYR1_precision: 0.71, RYR1_recall: 0.71, GJB2_loss: 0.42, GJB2_accuracy: 83.0%, GJB2_auc: 0.91, GJB2_precision: 0.83, GJB2_recall: 0.83
-----------------------------------------------------------------
Vali - loss: 0.53±0.01, accuracy: 76.1±0.6%, auc: 0.84±0.01
Test - loss: 0.43±0.00, accuracy: 82.7±0.3%, auc: 0.90±0.00
GJB2 - loss: 0.40±0.01, accuracy: 84.3±1.9%, auc: 0.92±0.01
RYR1 - loss: 0.59±0.01, accuracy: 71.3±1.5%, auc: 0.78±0.01
-----------------------------------------------------------------
Input Layer: 33
Model Configuration: 
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Layer   | Activation | Batch Norm | Dropout Rate |  Initializer   | L1 |   L2   | N Neurons |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Input   |     -      |     -      |     0.0      |       -        | -  |   -    |     33    |
| hidden_00 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_01 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_02 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_03 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_04 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_05 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_06 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_07 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_08 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_09 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     10    |
|   Output  |  softmax   |     -      |      -       |       -        | -  |   -    |     2     |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
Training Configuration: 
+-----------+------------+----------+--------------------------+---------------------+
|  Training | Batch Size | N Epochs |           Loss           |       Metrics       |
+-----------+------------+----------+--------------------------+---------------------+
|  Training |    300     |   300    | categorical_crossentropy | ['accuracy', 'AUC'] |
| Optimizer |   5e-05    |  Nadam   |            -             |          -          |
+-----------+------------+----------+--------------------------+---------------------+
Number of parameters: 10460
Fold 1 - val_loss: 0.54, val_accuracy: 75.2%, val_auc: 0.83, val_precision: 0.75, val_recall: 0.75, test_loss: 0.46, test_accuracy: 81.5%, test_auc: 0.89, test_precision: 0.82, test_recall: 0.82, RYR1_loss: 0.58, RYR1_accuracy: 76.7%, RYR1_auc: 0.80, RYR1_precision: 0.77, RYR1_recall: 0.77, GJB2_loss: 0.37, GJB2_accuracy: 87.2%, GJB2_auc: 0.93, GJB2_precision: 0.87, GJB2_recall: 0.87
Fold 2 - val_loss: 0.50, val_accuracy: 78.7%, val_auc: 0.86, val_precision: 0.79, val_recall: 0.79, test_loss: 0.45, test_accuracy: 83.4%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.59, RYR1_accuracy: 71.1%, RYR1_auc: 0.79, RYR1_precision: 0.71, RYR1_recall: 0.71, GJB2_loss: 0.43, GJB2_accuracy: 83.0%, GJB2_auc: 0.92, GJB2_precision: 0.83, GJB2_recall: 0.83
Fold 3 - val_loss: 0.56, val_accuracy: 75.3%, val_auc: 0.82, val_precision: 0.75, val_recall: 0.75, test_loss: 0.45, test_accuracy: 82.5%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.62, RYR1_accuracy: 66.7%, RYR1_auc: 0.76, RYR1_precision: 0.67, RYR1_recall: 0.67, GJB2_loss: 0.40, GJB2_accuracy: 83.0%, GJB2_auc: 0.93, GJB2_precision: 0.83, GJB2_recall: 0.83
Fold 4 - val_loss: 0.54, val_accuracy: 75.7%, val_auc: 0.83, val_precision: 0.76, val_recall: 0.76, test_loss: 0.44, test_accuracy: 82.4%, test_auc: 0.90, test_precision: 0.82, test_recall: 0.82, RYR1_loss: 0.61, RYR1_accuracy: 71.1%, RYR1_auc: 0.76, RYR1_precision: 0.71, RYR1_recall: 0.71, GJB2_loss: 0.42, GJB2_accuracy: 80.9%, GJB2_auc: 0.91, GJB2_precision: 0.81, GJB2_recall: 0.81
Fold 5 - val_loss: 0.53, val_accuracy: 76.2%, val_auc: 0.84, val_precision: 0.76, val_recall: 0.76, test_loss: 0.47, test_accuracy: 82.8%, test_auc: 0.89, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.61, RYR1_accuracy: 72.2%, RYR1_auc: 0.76, RYR1_precision: 0.72, RYR1_recall: 0.72, GJB2_loss: 0.41, GJB2_accuracy: 89.4%, GJB2_auc: 0.92, GJB2_precision: 0.89, GJB2_recall: 0.89
-----------------------------------------------------------------
Vali - loss: 0.53±0.01, accuracy: 76.2±0.6%, auc: 0.84±0.01
Test - loss: 0.45±0.01, accuracy: 82.5±0.3%, auc: 0.90±0.00
GJB2 - loss: 0.41±0.01, accuracy: 84.7±1.6%, auc: 0.92±0.00
RYR1 - loss: 0.60±0.01, accuracy: 71.6±1.6%, auc: 0.77±0.01
-----------------------------------------------------------------
Input Layer: 33
Model Configuration: 
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Layer   | Activation | Batch Norm | Dropout Rate |  Initializer   | L1 |   L2   | N Neurons |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Input   |     -      |     -      |     0.0      |       -        | -  |   -    |     33    |
| hidden_00 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_01 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_02 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_03 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_04 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_05 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_06 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_07 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_08 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_09 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_10 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_11 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     10    |
|   Output  |  softmax   |     -      |      -       |       -        | -  |   -    |     2     |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
Training Configuration: 
+-----------+------------+----------+--------------------------+---------------------+
|  Training | Batch Size | N Epochs |           Loss           |       Metrics       |
+-----------+------------+----------+--------------------------+---------------------+
|  Training |    300     |   300    | categorical_crossentropy | ['accuracy', 'AUC'] |
| Optimizer |   5e-05    |  Nadam   |            -             |          -          |
+-----------+------------+----------+--------------------------+---------------------+
Number of parameters: 12704
Fold 1 - val_loss: 0.54, val_accuracy: 75.3%, val_auc: 0.83, val_precision: 0.75, val_recall: 0.75, test_loss: 0.47, test_accuracy: 81.3%, test_auc: 0.89, test_precision: 0.81, test_recall: 0.81, RYR1_loss: 0.58, RYR1_accuracy: 75.6%, RYR1_auc: 0.80, RYR1_precision: 0.76, RYR1_recall: 0.76, GJB2_loss: 0.37, GJB2_accuracy: 87.2%, GJB2_auc: 0.93, GJB2_precision: 0.87, GJB2_recall: 0.87
Fold 2 - val_loss: 0.51, val_accuracy: 78.2%, val_auc: 0.85, val_precision: 0.78, val_recall: 0.78, test_loss: 0.45, test_accuracy: 83.0%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.60, RYR1_accuracy: 72.2%, RYR1_auc: 0.78, RYR1_precision: 0.72, RYR1_recall: 0.72, GJB2_loss: 0.43, GJB2_accuracy: 83.0%, GJB2_auc: 0.91, GJB2_precision: 0.83, GJB2_recall: 0.83
Fold 3 - val_loss: 0.56, val_accuracy: 75.5%, val_auc: 0.82, val_precision: 0.76, val_recall: 0.76, test_loss: 0.47, test_accuracy: 82.2%, test_auc: 0.89, test_precision: 0.82, test_recall: 0.82, RYR1_loss: 0.62, RYR1_accuracy: 67.8%, RYR1_auc: 0.76, RYR1_precision: 0.68, RYR1_recall: 0.68, GJB2_loss: 0.40, GJB2_accuracy: 83.0%, GJB2_auc: 0.93, GJB2_precision: 0.83, GJB2_recall: 0.83
Fold 4 - val_loss: 0.54, val_accuracy: 75.8%, val_auc: 0.83, val_precision: 0.76, val_recall: 0.76, test_loss: 0.44, test_accuracy: 81.9%, test_auc: 0.90, test_precision: 0.82, test_recall: 0.82, RYR1_loss: 0.61, RYR1_accuracy: 72.2%, RYR1_auc: 0.76, RYR1_precision: 0.72, RYR1_recall: 0.72, GJB2_loss: 0.42, GJB2_accuracy: 80.9%, GJB2_auc: 0.91, GJB2_precision: 0.81, GJB2_recall: 0.81
Fold 5 - val_loss: 0.53, val_accuracy: 76.2%, val_auc: 0.84, val_precision: 0.76, val_recall: 0.76, test_loss: 0.45, test_accuracy: 82.9%, test_auc: 0.90, test_precision: 0.83, test_recall: 0.83, RYR1_loss: 0.61, RYR1_accuracy: 72.2%, RYR1_auc: 0.77, RYR1_precision: 0.72, RYR1_recall: 0.72, GJB2_loss: 0.42, GJB2_accuracy: 85.1%, GJB2_auc: 0.92, GJB2_precision: 0.85, GJB2_recall: 0.85
-----------------------------------------------------------------
Vali - loss: 0.54±0.01, accuracy: 76.2±0.5%, auc: 0.84±0.01
Test - loss: 0.46±0.01, accuracy: 82.3±0.3%, auc: 0.89±0.00
GJB2 - loss: 0.41±0.01, accuracy: 83.8±1.1%, auc: 0.92±0.00
RYR1 - loss: 0.60±0.01, accuracy: 72.0±1.2%, auc: 0.77±0.01
-----------------------------------------------------------------
End Time = 20250418-1202
##################################################
