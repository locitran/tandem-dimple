Start Time = 20250419-1150
Num GPUs Available: 0
GPUs: []
**************************************************
Feature selection based on ttest rank
/mnt/nas_1/YangLab/loci/tandem/data/R20000/stats/features_stats.csv
Feature set: ['GNM_co_rank_full', 'ANM_stiffness_chain', 'GNM_V2_full', 'GNM_V1_full', 'GNM_Eigval1_full', 'GNM_rankV2_full', 'GNM_Eigval2_full', 'GNM_rankV1_full', 'ANM_effectiveness_chain', 'SASA', 'loop_percent', 'AG1', 'Dcom', 'AG5', 'AG3', 'SSbond', 'Hbond', 'DELTA_Hbond', 'sheet_percent', 'helix_percent', 'Rg', 'IDRs', 'Lside', 'deltaLside', 'entropy', 'wtPSIC', 'deltaPSIC', 'consurf', 'ACNR', 'BLOSUM', 'ranked_MI', 'deltaPolarity', 'deltaCharge']
**************************************************
Missing values in the dataframe:
consurf: 		 2
ACNR: 		 2
deltaPSIC: 		 1
SF1: 		 11
SF2: 		 11
SF3: 		 11
entropy: 		 3769
ranked_MI: 		 3769
Assigning the mean value of feature to the missing values
Assigning mean value to consurf: -0.23
Assigning mean value to ACNR: -0.18
Assigning mean value to deltaPSIC: 1.83
Assigning mean value to SF1: 0.50
Assigning mean value to SF2: 0.67
Assigning mean value to SF3: 0.76
Assigning mean value to entropy: 1.65
Assigning mean value to ranked_MI: 0.48
**************************************************
1 members: 1428 clusters
2 members: 226 clusters
3 members: 57 clusters
4 members: 24 clusters
5 members: 18 clusters
7 members: 8 clusters
6 members: 6 clusters
9 members: 3 clusters
8 members: 2 clusters
36 members: 1 clusters
10 members: 1 clusters
No. UniProtID: 2423, No. SAVs: 20361, and No. clusters: 1774
No. pathogenic SAVs: 13626 and benign SAVs: 6735
**************************************************
> Deleting cluster P29033 from data_sorted
No. clusters: 1773
No. SAVs after deleting P29033: 20295
**************************************************
> Adding cluster P29033 to the test set
Test set percent = 10.03% is larger than 10%: Breaking the loop
No. adding to test set: 34
Cluster IDs added to the test set: [67, 5, 11, 17, 23, 29, 35, 41, 47, 53, 59, 65, 72, 78, 84, 90, 96, 102, 108, 114, 120, 126, 132, 138, 144, 150, 156, 162, 168, 174, 180, 186, 192, 198]
Member IDs added to the test set: ['P29033', 'P07101', 'Q8IWU9', 'P00439', 'Q9UHC9', 'O15118', 'P22304', 'P30613', 'P14618', 'P35520', 'P11509', 'Q16696', 'P05181', 'P20813', 'P11712', 'P10632', 'P33261', 'P00966', 'P11413', 'Q93099', 'P15848', 'P54802', 'P60484', 'Q06124', 'P09619', 'P16234', 'P10721', 'P07333', 'P78504', 'Q9NR61', 'P52701', 'Q15831', 'P08559', 'P06400', 'P00156', 'P78527', 'Q14353', 'Q13224', 'Q12879', 'Q9H251', 'P51648', 'P30838', 'P18074', 'O94759', 'Q8TD43', 'P00813', 'O14733', 'P36507', 'P45985', 'Q02750', 'Q96L73', 'O43240', 'P06870', 'P07288', 'P20151', 'O60259', 'Q9Y5K2', 'P23946', 'P07477', 'Q92876', 'P46597', 'P03891']
> Delete test indices from data_sorted
No. clusters after deleting test indices: 1740
No. SAVs after deleting test indices: 18596
**************************************************
> Adding cluster Q16874 P55735 P57740 Q12769 Q9BW27 to the training set
Q16874 SAVs: 71
Q16874 SAV coords: P55735 172 S L
Q16874 SAV labels: 0
**************************************************
> Adding cluster P04745 to the validation set
Fold 0: 
         Train: n_SAVs = 14651, % SAVs = 71.96%, n_pathogenic = 8967, n_benign = 5684, ratio = 1.58:1, n_clusters = 1652, n_members = 2189
         Val: n_SAVs = 3667, % SAVs = 18.01%, n_pathogenic = 3010, n_benign = 657, ratio = 4.58:1, n_clusters = 88, n_members = 168
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 1: 
         Train: n_SAVs = 14652, % SAVs = 71.96%, n_pathogenic = 9287, n_benign = 5365, ratio = 1.73:1, n_clusters = 1541, n_members = 2039
         Val: n_SAVs = 3666, % SAVs = 18.01%, n_pathogenic = 2690, n_benign = 976, ratio = 2.76:1, n_clusters = 199, n_members = 318
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 2: 
         Train: n_SAVs = 14653, % SAVs = 71.97%, n_pathogenic = 10113, n_benign = 4540, ratio = 2.23:1, n_clusters = 1403, n_members = 1861
         Val: n_SAVs = 3665, % SAVs = 18.00%, n_pathogenic = 1864, n_benign = 1801, ratio = 1.03:1, n_clusters = 337, n_members = 496
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 3: 
         Train: n_SAVs = 14653, % SAVs = 71.97%, n_pathogenic = 9852, n_benign = 4801, ratio = 2.05:1, n_clusters = 1255, n_members = 1733
         Val: n_SAVs = 3665, % SAVs = 18.00%, n_pathogenic = 2125, n_benign = 1540, ratio = 1.38:1, n_clusters = 485, n_members = 624
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 4: 
         Train: n_SAVs = 14663, % SAVs = 72.02%, n_pathogenic = 9689, n_benign = 4974, ratio = 1.95:1, n_clusters = 1109, n_members = 1606
         Val: n_SAVs = 3655, % SAVs = 17.95%, n_pathogenic = 2288, n_benign = 1367, ratio = 1.67:1, n_clusters = 631, n_members = 751
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
**************************************************
Missing values in the dataframe:
labels: 		 83
entropy: 		 6
ranked_MI: 		 6
No. Unknown SAVs 25 (benign), 22 (pathogenic), and 83 (NaN)
Input Layer: 33
Model Configuration: 
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Layer   | Activation | Batch Norm | Dropout Rate |  Initializer   | L1 |   L2   | N Neurons |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Input   |     -      |     -      |     0.0      |       -        | -  |   -    |     33    |
| hidden_00 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_01 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_02 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_03 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_04 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_05 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     10    |
|   Output  |  softmax   |     -      |      -       |       -        | -  |   -    |     2     |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
Training Configuration: 
+-----------+------------+----------+--------------------------+---------------------+
|  Training | Batch Size | N Epochs |           Loss           |       Metrics       |
+-----------+------------+----------+--------------------------+---------------------+
|  Training |    300     |   300    | categorical_crossentropy | ['accuracy', 'AUC'] |
| Optimizer |   5e-05    |  Nadam   |            -             |          -          |
+-----------+------------+----------+--------------------------+---------------------+
Start from epoch: 10
Fold 1 - Train: 14pos + 14neg, Val: 6pos + 8neg, Test: 2pos + 3neg)
Train: ['P29033 90 L P' 'P29033 179 D N' 'P29033 123 T N' 'P29033 215 I M'
 'P29033 44 W S' 'P29033 127 R H' 'P29033 170 N S' 'P29033 206 N S'
 'P29033 143 R W' 'P29033 44 W C' 'P29033 168 K R' 'P29033 84 V L'
 'P29033 4 G V' 'P29033 50 D N' 'P29033 121 I V' 'P29033 83 F L'
 'P29033 37 V I' 'P29033 34 M T' 'P29033 197 A S' 'P29033 111 I T'
 'P29033 156 V I' 'P29033 27 V I' 'P29033 153 V I' 'P29033 4 G D'
 'P29033 95 V M' 'P29033 205 L V' 'P29033 75 R W' 'P29033 210 L V']
Val: ['P29033 203 I T' 'P29033 202 C F' 'P29033 16 H Y' 'P29033 217 Y D'
 'P29033 75 R Q' 'P29033 214 L V' 'P29033 143 R Q' 'P29033 115 F V'
 'P29033 197 A T' 'P29033 170 N K' 'P29033 161 F S' 'P29033 184 R Q'
 'P29033 100 H Q' 'P29033 59 G A']
Test: ['P29033 107 I L' 'P29033 195 M T' 'P29033 114 E G' 'P29033 163 M T'
 'P29033 165 R W']
Fold 2 - Train: 13pos + 15neg, Val: 7pos + 7neg, Test: 2pos + 3neg)
Train: ['P29033 203 I T' 'P29033 202 C F' 'P29033 127 R H' 'P29033 16 H Y'
 'P29033 217 Y D' 'P29033 75 R Q' 'P29033 206 N S' 'P29033 214 L V'
 'P29033 44 W C' 'P29033 143 R Q' 'P29033 115 F V' 'P29033 121 I V'
 'P29033 197 A T' 'P29033 34 M T' 'P29033 197 A S' 'P29033 170 N K'
 'P29033 111 I T' 'P29033 27 V I' 'P29033 161 F S' 'P29033 184 R Q'
 'P29033 100 H Q' 'P29033 153 V I' 'P29033 4 G D' 'P29033 59 G A'
 'P29033 95 V M' 'P29033 205 L V' 'P29033 75 R W' 'P29033 210 L V']
Val: ['P29033 90 L P' 'P29033 179 D N' 'P29033 123 T N' 'P29033 215 I M'
 'P29033 44 W S' 'P29033 170 N S' 'P29033 143 R W' 'P29033 168 K R'
 'P29033 84 V L' 'P29033 4 G V' 'P29033 50 D N' 'P29033 83 F L'
 'P29033 37 V I' 'P29033 156 V I']
Test: ['P29033 107 I L' 'P29033 195 M T' 'P29033 114 E G' 'P29033 163 M T'
 'P29033 165 R W']
Fold 3 - Train: 13pos + 15neg, Val: 7pos + 7neg, Test: 2pos + 3neg)
Train: ['P29033 203 I T' 'P29033 90 L P' 'P29033 179 D N' 'P29033 202 C F'
 'P29033 123 T N' 'P29033 215 I M' 'P29033 44 W S' 'P29033 16 H Y'
 'P29033 217 Y D' 'P29033 170 N S' 'P29033 75 R Q' 'P29033 143 R W'
 'P29033 214 L V' 'P29033 168 K R' 'P29033 84 V L' 'P29033 143 R Q'
 'P29033 4 G V' 'P29033 115 F V' 'P29033 50 D N' 'P29033 83 F L'
 'P29033 37 V I' 'P29033 197 A T' 'P29033 170 N K' 'P29033 156 V I'
 'P29033 161 F S' 'P29033 184 R Q' 'P29033 100 H Q' 'P29033 59 G A']
Val: ['P29033 127 R H' 'P29033 206 N S' 'P29033 44 W C' 'P29033 121 I V'
 'P29033 34 M T' 'P29033 197 A S' 'P29033 111 I T' 'P29033 27 V I'
 'P29033 153 V I' 'P29033 4 G D' 'P29033 95 V M' 'P29033 205 L V'
 'P29033 75 R W' 'P29033 210 L V']
Test: ['P29033 107 I L' 'P29033 195 M T' 'P29033 114 E G' 'P29033 163 M T'
 'P29033 165 R W']
=.= No. 0
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.51, R20000_val_accuracy: 77.34%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.43, R20000_test_accuracy: 82.09%, R20000_test_auc: 0.90, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.44, val_accuracy: 85.71%, val_auc: 0.88, val_precision: 0.86, val_recall: 0.86, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 1 after - R20000_val_loss: 0.60, R20000_val_accuracy: 74.34%, R20000_val_auc: 0.80, R20000_val_precision: 0.74, R20000_val_recall: 0.74, R20000_test_loss: 0.45, R20000_test_accuracy: 80.86%, R20000_test_auc: 0.88, R20000_test_precision: 0.81, R20000_test_recall: 0.81, val_loss: 0.37, val_accuracy: 85.71%, val_auc: 0.93, val_precision: 0.86, val_recall: 0.86, test_loss: 0.22, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
P29033 107 I L	0.006	0
P29033 195 M T	0.945	1
P29033 114 E G	0.106	0
P29033 163 M T	0.903	1
P29033 165 R W	0.528	1
Predictions on val data
P29033 203 I T	0.899	1
P29033 202 C F	0.945	1
P29033 16 H Y	0.707	1
P29033 217 Y D	0.130	0
P29033 75 R Q	0.927	1
P29033 214 L V	0.031	0
P29033 143 R Q	0.943	1
P29033 115 F V	0.048	0
P29033 197 A T	0.334	0
P29033 170 N K	0.128	0
P29033 161 F S	0.960	1
P29033 184 R Q	0.937	1
P29033 100 H Q	0.251	0
P29033 59 G A	0.935	1
Fold 2 before - R20000_val_loss: 0.51, R20000_val_accuracy: 77.34%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.43, R20000_test_accuracy: 82.09%, R20000_test_auc: 0.90, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.27, val_accuracy: 100.00%, val_auc: 1.00, val_precision: 1.00, val_recall: 1.00, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 2 after - R20000_val_loss: 0.70, R20000_val_accuracy: 70.06%, R20000_val_auc: 0.77, R20000_val_precision: 0.70, R20000_val_recall: 0.70, R20000_test_loss: 0.49, R20000_test_accuracy: 78.71%, R20000_test_auc: 0.87, R20000_test_precision: 0.79, R20000_test_recall: 0.79, val_loss: 0.23, val_accuracy: 92.86%, val_auc: 0.98, val_precision: 0.93, val_recall: 0.93, test_loss: 0.19, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.003	0
P29033 195 M T	0.950	1
P29033 114 E G	0.051	0
P29033 163 M T	0.815	1
P29033 165 R W	0.422	0
Predictions on val data
P29033 90 L P	0.939	1
P29033 179 D N	0.793	1
P29033 123 T N	0.010	0
P29033 215 I M	0.028	0
P29033 44 W S	0.988	1
P29033 170 N S	0.056	0
P29033 143 R W	0.968	1
P29033 168 K R	0.115	0
P29033 84 V L	0.917	1
P29033 4 G V	0.107	0
P29033 50 D N	0.600	1
P29033 83 F L	0.176	0
P29033 37 V I	0.218	0
P29033 156 V I	0.016	0
Fold 3 before - R20000_val_loss: 0.51, R20000_val_accuracy: 77.34%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.43, R20000_test_accuracy: 82.09%, R20000_test_auc: 0.90, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.50, val_accuracy: 71.43%, val_auc: 0.86, val_precision: 0.71, val_recall: 0.71, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 3 after - R20000_val_loss: 0.56, R20000_val_accuracy: 74.91%, R20000_val_auc: 0.81, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.45, R20000_test_accuracy: 80.81%, R20000_test_auc: 0.88, R20000_test_precision: 0.81, R20000_test_recall: 0.81, val_loss: 0.49, val_accuracy: 78.57%, val_auc: 0.88, val_precision: 0.79, val_recall: 0.79, test_loss: 0.25, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.017	0
P29033 195 M T	0.893	1
P29033 114 E G	0.189	0
P29033 163 M T	0.784	1
P29033 165 R W	0.439	0
Predictions on val data
P29033 127 R H	0.127	0
P29033 206 N S	0.780	1
P29033 44 W C	0.933	1
P29033 121 I V	0.015	0
P29033 34 M T	0.221	0
P29033 197 A S	0.135	0
P29033 111 I T	0.018	0
P29033 27 V I	0.673	1
P29033 153 V I	0.060	0
P29033 4 G D	0.484	0
P29033 95 V M	0.851	1
P29033 205 L V	0.868	1
P29033 75 R W	0.887	1
P29033 210 L V	0.280	0
Before Training
-----------------------------------------------------------------R20000_val_loss	0.51±0.00, R20000_val_accuracy	77.34±0.00%, 
R20000_test_loss	0.43±0.00, R20000_test_accuracy	82.09±0.00%, 
val_loss	0.41±0.07, val_accuracy	85.71±8.25%, 
test_loss	0.31±0.00, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.62±0.04, R20000_val_accuracy	73.10±1.53%, 
R20000_test_loss	0.46±0.02, R20000_test_accuracy	80.13±0.71%, 
val_loss	0.36±0.07, val_accuracy	85.71±4.12%, 
test_loss	0.22±0.02, test_accuracy	93.33±6.67%, 
-----------------------------------------------------------------
=.= No. 1
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.44, R20000_val_accuracy: 81.78%, R20000_val_auc: 0.89, R20000_val_precision: 0.82, R20000_val_recall: 0.82, R20000_test_loss: 0.39, R20000_test_accuracy: 84.39%, R20000_test_auc: 0.92, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.42, val_accuracy: 85.71%, val_auc: 0.93, val_precision: 0.86, val_recall: 0.86, test_loss: 0.35, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
Fold 1 after - R20000_val_loss: 0.47, R20000_val_accuracy: 80.91%, R20000_val_auc: 0.88, R20000_val_precision: 0.81, R20000_val_recall: 0.81, R20000_test_loss: 0.41, R20000_test_accuracy: 83.50%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.30, val_accuracy: 92.86%, val_auc: 0.95, val_precision: 0.93, val_recall: 0.93, test_loss: 0.25, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
P29033 107 I L	0.007	0
P29033 195 M T	0.955	1
P29033 114 E G	0.101	0
P29033 163 M T	0.910	1
P29033 165 R W	0.603	1
Predictions on val data
P29033 203 I T	0.874	1
P29033 202 C F	0.941	1
P29033 16 H Y	0.493	0
P29033 217 Y D	0.214	0
P29033 75 R Q	0.940	1
P29033 214 L V	0.040	0
P29033 143 R Q	0.946	1
P29033 115 F V	0.040	0
P29033 197 A T	0.279	0
P29033 170 N K	0.127	0
P29033 161 F S	0.964	1
P29033 184 R Q	0.949	1
P29033 100 H Q	0.179	0
P29033 59 G A	0.951	1
Fold 2 before - R20000_val_loss: 0.44, R20000_val_accuracy: 81.78%, R20000_val_auc: 0.89, R20000_val_precision: 0.82, R20000_val_recall: 0.82, R20000_test_loss: 0.39, R20000_test_accuracy: 84.39%, R20000_test_auc: 0.92, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.32, val_accuracy: 100.00%, val_auc: 1.00, val_precision: 1.00, val_recall: 1.00, test_loss: 0.35, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
Fold 2 after - R20000_val_loss: 0.50, R20000_val_accuracy: 79.81%, R20000_val_auc: 0.87, R20000_val_precision: 0.80, R20000_val_recall: 0.80, R20000_test_loss: 0.44, R20000_test_accuracy: 82.13%, R20000_test_auc: 0.90, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.24, val_accuracy: 92.86%, val_auc: 0.97, val_precision: 0.93, val_recall: 0.93, test_loss: 0.22, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
P29033 107 I L	0.006	0
P29033 195 M T	0.957	1
P29033 114 E G	0.060	0
P29033 163 M T	0.799	1
P29033 165 R W	0.507	1
Predictions on val data
P29033 90 L P	0.923	1
P29033 179 D N	0.836	1
P29033 123 T N	0.017	0
P29033 215 I M	0.041	0
P29033 44 W S	0.994	1
P29033 170 N S	0.067	0
P29033 143 R W	0.975	1
P29033 168 K R	0.136	0
P29033 84 V L	0.914	1
P29033 4 G V	0.134	0
P29033 50 D N	0.621	1
P29033 83 F L	0.195	0
P29033 37 V I	0.182	0
P29033 156 V I	0.029	0
Fold 3 before - R20000_val_loss: 0.44, R20000_val_accuracy: 81.78%, R20000_val_auc: 0.89, R20000_val_precision: 0.82, R20000_val_recall: 0.82, R20000_test_loss: 0.39, R20000_test_accuracy: 84.39%, R20000_test_auc: 0.92, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.54, val_accuracy: 71.43%, val_auc: 0.86, val_precision: 0.71, val_recall: 0.71, test_loss: 0.35, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
Fold 3 after - R20000_val_loss: 0.45, R20000_val_accuracy: 81.04%, R20000_val_auc: 0.88, R20000_val_precision: 0.81, R20000_val_recall: 0.81, R20000_test_loss: 0.40, R20000_test_accuracy: 83.70%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.52, val_accuracy: 71.43%, val_auc: 0.85, val_precision: 0.71, val_recall: 0.71, test_loss: 0.27, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.019	0
P29033 195 M T	0.896	1
P29033 114 E G	0.210	0
P29033 163 M T	0.763	1
P29033 165 R W	0.478	0
Predictions on val data
P29033 127 R H	0.131	0
P29033 206 N S	0.807	1
P29033 44 W C	0.952	1
P29033 121 I V	0.017	0
P29033 34 M T	0.188	0
P29033 197 A S	0.114	0
P29033 111 I T	0.015	0
P29033 27 V I	0.686	1
P29033 153 V I	0.070	0
P29033 4 G D	0.563	1
P29033 95 V M	0.830	1
P29033 205 L V	0.856	1
P29033 75 R W	0.898	1
P29033 210 L V	0.248	0
Before Training
-----------------------------------------------------------------R20000_val_loss	0.44±0.00, R20000_val_accuracy	81.78±0.00%, 
R20000_test_loss	0.39±0.00, R20000_test_accuracy	84.39±0.00%, 
val_loss	0.43±0.06, val_accuracy	85.71±8.25%, 
test_loss	0.35±0.00, test_accuracy	80.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.47±0.02, R20000_val_accuracy	80.59±0.39%, 
R20000_test_loss	0.42±0.01, R20000_test_accuracy	83.11±0.49%, 
val_loss	0.36±0.08, val_accuracy	85.71±7.14%, 
test_loss	0.25±0.01, test_accuracy	86.67±6.67%, 
-----------------------------------------------------------------
=.= No. 2
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.51, R20000_val_accuracy: 76.89%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.40, R20000_test_accuracy: 83.99%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.47, val_accuracy: 85.71%, val_auc: 0.85, val_precision: 0.86, val_recall: 0.86, test_loss: 0.34, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 1 after - R20000_val_loss: 0.54, R20000_val_accuracy: 77.16%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.43, R20000_test_accuracy: 82.43%, R20000_test_auc: 0.89, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.34, val_accuracy: 85.71%, val_auc: 0.94, val_precision: 0.86, val_recall: 0.86, test_loss: 0.21, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.007	0
P29033 195 M T	0.958	1
P29033 114 E G	0.144	0
P29033 163 M T	0.935	1
P29033 165 R W	0.496	0
Predictions on val data
P29033 203 I T	0.918	1
P29033 202 C F	0.950	1
P29033 16 H Y	0.518	1
P29033 217 Y D	0.215	0
P29033 75 R Q	0.935	1
P29033 214 L V	0.040	0
P29033 143 R Q	0.949	1
P29033 115 F V	0.054	0
P29033 197 A T	0.297	0
P29033 170 N K	0.149	0
P29033 161 F S	0.974	1
P29033 184 R Q	0.946	1
P29033 100 H Q	0.151	0
P29033 59 G A	0.946	1
Fold 2 before - R20000_val_loss: 0.51, R20000_val_accuracy: 76.89%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.40, R20000_test_accuracy: 83.99%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.31, val_accuracy: 92.86%, val_auc: 0.99, val_precision: 0.93, val_recall: 0.93, test_loss: 0.34, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 2 after - R20000_val_loss: 0.55, R20000_val_accuracy: 77.35%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.46, R20000_test_accuracy: 81.45%, R20000_test_auc: 0.88, R20000_test_precision: 0.81, R20000_test_recall: 0.81, val_loss: 0.25, val_accuracy: 92.86%, val_auc: 0.96, val_precision: 0.93, val_recall: 0.93, test_loss: 0.19, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.006	0
P29033 195 M T	0.944	1
P29033 114 E G	0.091	0
P29033 163 M T	0.853	1
P29033 165 R W	0.423	0
Predictions on val data
P29033 90 L P	0.940	1
P29033 179 D N	0.770	1
P29033 123 T N	0.019	0
P29033 215 I M	0.047	0
P29033 44 W S	0.985	1
P29033 170 N S	0.050	0
P29033 143 R W	0.952	1
P29033 168 K R	0.101	0
P29033 84 V L	0.922	1
P29033 4 G V	0.157	0
P29033 50 D N	0.598	1
P29033 83 F L	0.214	0
P29033 37 V I	0.187	0
P29033 156 V I	0.023	0
Fold 3 before - R20000_val_loss: 0.51, R20000_val_accuracy: 76.89%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.40, R20000_test_accuracy: 83.99%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.55, val_accuracy: 64.29%, val_auc: 0.84, val_precision: 0.64, val_recall: 0.64, test_loss: 0.34, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 3 after - R20000_val_loss: 0.52, R20000_val_accuracy: 77.24%, R20000_val_auc: 0.85, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.42, R20000_test_accuracy: 82.97%, R20000_test_auc: 0.90, R20000_test_precision: 0.83, R20000_test_recall: 0.83, val_loss: 0.51, val_accuracy: 78.57%, val_auc: 0.86, val_precision: 0.79, val_recall: 0.79, test_loss: 0.22, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.014	0
P29033 195 M T	0.916	1
P29033 114 E G	0.242	0
P29033 163 M T	0.845	1
P29033 165 R W	0.380	0
Predictions on val data
P29033 127 R H	0.093	0
P29033 206 N S	0.835	1
P29033 44 W C	0.959	1
P29033 121 I V	0.012	0
P29033 34 M T	0.208	0
P29033 197 A S	0.093	0
P29033 111 I T	0.015	0
P29033 27 V I	0.735	1
P29033 153 V I	0.042	0
P29033 4 G D	0.491	0
P29033 95 V M	0.869	1
P29033 205 L V	0.901	1
P29033 75 R W	0.904	1
P29033 210 L V	0.246	0
Before Training
-----------------------------------------------------------------R20000_val_loss	0.51±0.00, R20000_val_accuracy	76.89±0.00%, 
R20000_test_loss	0.40±0.00, R20000_test_accuracy	83.99±0.00%, 
val_loss	0.44±0.07, val_accuracy	80.95±8.58%, 
test_loss	0.34±0.00, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.54±0.01, R20000_val_accuracy	77.25±0.06%, 
R20000_test_loss	0.44±0.01, R20000_test_accuracy	82.28±0.44%, 
val_loss	0.37±0.08, val_accuracy	85.71±4.12%, 
test_loss	0.20±0.01, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------
=.= No. 3
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.49, R20000_val_accuracy: 77.76%, R20000_val_auc: 0.86, R20000_val_precision: 0.78, R20000_val_recall: 0.78, R20000_test_loss: 0.39, R20000_test_accuracy: 84.04%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.46, val_accuracy: 78.57%, val_auc: 0.87, val_precision: 0.79, val_recall: 0.79, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 1 after - R20000_val_loss: 0.54, R20000_val_accuracy: 77.41%, R20000_val_auc: 0.85, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.43, R20000_test_accuracy: 82.67%, R20000_test_auc: 0.89, R20000_test_precision: 0.83, R20000_test_recall: 0.83, val_loss: 0.31, val_accuracy: 92.86%, val_auc: 0.95, val_precision: 0.93, val_recall: 0.93, test_loss: 0.15, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.003	0
P29033 195 M T	0.955	1
P29033 114 E G	0.057	0
P29033 163 M T	0.928	1
P29033 165 R W	0.385	0
Predictions on val data
P29033 203 I T	0.911	1
P29033 202 C F	0.946	1
P29033 16 H Y	0.437	0
P29033 217 Y D	0.216	0
P29033 75 R Q	0.936	1
P29033 214 L V	0.024	0
P29033 143 R Q	0.946	1
P29033 115 F V	0.035	0
P29033 197 A T	0.290	0
P29033 170 N K	0.131	0
P29033 161 F S	0.977	1
P29033 184 R Q	0.943	1
P29033 100 H Q	0.076	0
P29033 59 G A	0.951	1
Fold 2 before - R20000_val_loss: 0.49, R20000_val_accuracy: 77.76%, R20000_val_auc: 0.86, R20000_val_precision: 0.78, R20000_val_recall: 0.78, R20000_test_loss: 0.39, R20000_test_accuracy: 84.04%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.33, val_accuracy: 92.86%, val_auc: 0.98, val_precision: 0.93, val_recall: 0.93, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 2 after - R20000_val_loss: 0.56, R20000_val_accuracy: 76.29%, R20000_val_auc: 0.84, R20000_val_precision: 0.76, R20000_val_recall: 0.76, R20000_test_loss: 0.46, R20000_test_accuracy: 80.67%, R20000_test_auc: 0.88, R20000_test_precision: 0.81, R20000_test_recall: 0.81, val_loss: 0.25, val_accuracy: 92.86%, val_auc: 0.96, val_precision: 0.93, val_recall: 0.93, test_loss: 0.16, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.004	0
P29033 195 M T	0.943	1
P29033 114 E G	0.048	0
P29033 163 M T	0.789	1
P29033 165 R W	0.304	0
Predictions on val data
P29033 90 L P	0.939	1
P29033 179 D N	0.758	1
P29033 123 T N	0.013	0
P29033 215 I M	0.043	0
P29033 44 W S	0.989	1
P29033 170 N S	0.063	0
P29033 143 R W	0.960	1
P29033 168 K R	0.091	0
P29033 84 V L	0.909	1
P29033 4 G V	0.115	0
P29033 50 D N	0.561	1
P29033 83 F L	0.204	0
P29033 37 V I	0.188	0
P29033 156 V I	0.034	0
Fold 3 before - R20000_val_loss: 0.49, R20000_val_accuracy: 77.76%, R20000_val_auc: 0.86, R20000_val_precision: 0.78, R20000_val_recall: 0.78, R20000_test_loss: 0.39, R20000_test_accuracy: 84.04%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.57, val_accuracy: 71.43%, val_auc: 0.83, val_precision: 0.71, val_recall: 0.71, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 3 after - R20000_val_loss: 0.51, R20000_val_accuracy: 77.57%, R20000_val_auc: 0.86, R20000_val_precision: 0.78, R20000_val_recall: 0.78, R20000_test_loss: 0.42, R20000_test_accuracy: 82.97%, R20000_test_auc: 0.90, R20000_test_precision: 0.83, R20000_test_recall: 0.83, val_loss: 0.51, val_accuracy: 71.43%, val_auc: 0.86, val_precision: 0.71, val_recall: 0.71, test_loss: 0.17, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.008	0
P29033 195 M T	0.907	1
P29033 114 E G	0.116	0
P29033 163 M T	0.796	1
P29033 165 R W	0.292	0
Predictions on val data
P29033 127 R H	0.058	0
P29033 206 N S	0.794	1
P29033 44 W C	0.959	1
P29033 121 I V	0.009	0
P29033 34 M T	0.191	0
P29033 197 A S	0.105	0
P29033 111 I T	0.015	0
P29033 27 V I	0.714	1
P29033 153 V I	0.073	0
P29033 4 G D	0.530	1
P29033 95 V M	0.849	1
P29033 205 L V	0.882	1
P29033 75 R W	0.919	1
P29033 210 L V	0.211	0
Before Training
-----------------------------------------------------------------R20000_val_loss	0.49±0.00, R20000_val_accuracy	77.76±0.00%, 
R20000_test_loss	0.39±0.00, R20000_test_accuracy	84.04±0.00%, 
val_loss	0.45±0.07, val_accuracy	80.95±6.30%, 
test_loss	0.31±0.00, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.54±0.01, R20000_val_accuracy	77.09±0.40%, 
R20000_test_loss	0.44±0.01, R20000_test_accuracy	82.10±0.72%, 
val_loss	0.36±0.08, val_accuracy	85.71±7.14%, 
test_loss	0.16±0.01, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------
=.= No. 4
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.53, R20000_val_accuracy: 75.21%, R20000_val_auc: 0.83, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.40, R20000_test_accuracy: 83.55%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.41, val_accuracy: 85.71%, val_auc: 0.94, val_precision: 0.86, val_recall: 0.86, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 1 after - R20000_val_loss: 0.58, R20000_val_accuracy: 75.38%, R20000_val_auc: 0.82, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.43, R20000_test_accuracy: 82.77%, R20000_test_auc: 0.90, R20000_test_precision: 0.83, R20000_test_recall: 0.83, val_loss: 0.29, val_accuracy: 92.86%, val_auc: 0.95, val_precision: 0.93, val_recall: 0.93, test_loss: 0.21, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
P29033 107 I L	0.005	0
P29033 195 M T	0.954	1
P29033 114 E G	0.070	0
P29033 163 M T	0.920	1
P29033 165 R W	0.525	1
Predictions on val data
P29033 203 I T	0.877	1
P29033 202 C F	0.949	1
P29033 16 H Y	0.401	0
P29033 217 Y D	0.117	0
P29033 75 R Q	0.938	1
P29033 214 L V	0.044	0
P29033 143 R Q	0.954	1
P29033 115 F V	0.041	0
P29033 197 A T	0.325	0
P29033 170 N K	0.162	0
P29033 161 F S	0.969	1
P29033 184 R Q	0.938	1
P29033 100 H Q	0.171	0
P29033 59 G A	0.960	1
Fold 2 before - R20000_val_loss: 0.53, R20000_val_accuracy: 75.21%, R20000_val_auc: 0.83, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.40, R20000_test_accuracy: 83.55%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.34, val_accuracy: 92.86%, val_auc: 0.99, val_precision: 0.93, val_recall: 0.93, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 2 after - R20000_val_loss: 0.60, R20000_val_accuracy: 75.13%, R20000_val_auc: 0.82, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.45, R20000_test_accuracy: 81.35%, R20000_test_auc: 0.89, R20000_test_precision: 0.81, R20000_test_recall: 0.81, val_loss: 0.25, val_accuracy: 92.86%, val_auc: 0.97, val_precision: 0.93, val_recall: 0.93, test_loss: 0.20, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.005	0
P29033 195 M T	0.949	1
P29033 114 E G	0.047	0
P29033 163 M T	0.759	1
P29033 165 R W	0.411	0
Predictions on val data
P29033 90 L P	0.941	1
P29033 179 D N	0.673	1
P29033 123 T N	0.018	0
P29033 215 I M	0.038	0
P29033 44 W S	0.993	1
P29033 170 N S	0.085	0
P29033 143 R W	0.986	1
P29033 168 K R	0.139	0
P29033 84 V L	0.917	1
P29033 4 G V	0.147	0
P29033 50 D N	0.536	1
P29033 83 F L	0.166	0
P29033 37 V I	0.228	0
P29033 156 V I	0.027	0
Fold 3 before - R20000_val_loss: 0.53, R20000_val_accuracy: 75.21%, R20000_val_auc: 0.83, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.40, R20000_test_accuracy: 83.55%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.52, val_accuracy: 71.43%, val_auc: 0.86, val_precision: 0.71, val_recall: 0.71, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 3 after - R20000_val_loss: 0.54, R20000_val_accuracy: 75.76%, R20000_val_auc: 0.83, R20000_val_precision: 0.76, R20000_val_recall: 0.76, R20000_test_loss: 0.41, R20000_test_accuracy: 83.16%, R20000_test_auc: 0.90, R20000_test_precision: 0.83, R20000_test_recall: 0.83, val_loss: 0.51, val_accuracy: 71.43%, val_auc: 0.87, val_precision: 0.71, val_recall: 0.71, test_loss: 0.23, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 107 I L	0.017	0
P29033 195 M T	0.896	1
P29033 114 E G	0.161	0
P29033 163 M T	0.785	1
P29033 165 R W	0.418	0
Predictions on val data
P29033 127 R H	0.129	0
P29033 206 N S	0.804	1
P29033 44 W C	0.961	1
P29033 121 I V	0.021	0
P29033 34 M T	0.194	0
P29033 197 A S	0.155	0
P29033 111 I T	0.015	0
P29033 27 V I	0.701	1
P29033 153 V I	0.076	0
P29033 4 G D	0.597	1
P29033 95 V M	0.833	1
P29033 205 L V	0.852	1
P29033 75 R W	0.916	1
P29033 210 L V	0.265	0
Before Training
-----------------------------------------------------------------R20000_val_loss	0.53±0.00, R20000_val_accuracy	75.21±0.00%, 
R20000_test_loss	0.40±0.00, R20000_test_accuracy	83.55±0.00%, 
val_loss	0.42±0.06, val_accuracy	83.33±6.30%, 
test_loss	0.31±0.00, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.58±0.02, R20000_val_accuracy	75.42±0.18%, 
R20000_test_loss	0.43±0.01, R20000_test_accuracy	82.43±0.55%, 
val_loss	0.35±0.08, val_accuracy	85.71±7.14%, 
test_loss	0.21±0.01, test_accuracy	93.33±6.67%, 
-----------------------------------------------------------------
End Time = 20250419-1153
##################################################
