Start Time = 20250419-1200
Num GPUs Available: 0
GPUs: []
seed = 73
**************************************************
Feature selection based on ttest rank
/mnt/nas_1/YangLab/loci/tandem/data/R20000/stats/features_stats.csv
Feature set: ['GNM_co_rank_full', 'ANM_stiffness_chain', 'GNM_V2_full', 'GNM_V1_full', 'GNM_Eigval1_full', 'GNM_rankV2_full', 'GNM_Eigval2_full', 'GNM_rankV1_full', 'ANM_effectiveness_chain', 'SASA', 'loop_percent', 'AG1', 'Dcom', 'AG5', 'AG3', 'SSbond', 'Hbond', 'DELTA_Hbond', 'sheet_percent', 'helix_percent', 'Rg', 'IDRs', 'Lside', 'deltaLside', 'entropy', 'wtPSIC', 'deltaPSIC', 'consurf', 'ACNR', 'BLOSUM', 'ranked_MI', 'deltaPolarity', 'deltaCharge']
**************************************************
Missing values in the dataframe:
consurf: 		 2
ACNR: 		 2
deltaPSIC: 		 1
SF1: 		 11
SF2: 		 11
SF3: 		 11
entropy: 		 3769
ranked_MI: 		 3769
Assigning the mean value of feature to the missing values
Assigning mean value to consurf: -0.23
Assigning mean value to ACNR: -0.18
Assigning mean value to deltaPSIC: 1.83
Assigning mean value to SF1: 0.50
Assigning mean value to SF2: 0.67
Assigning mean value to SF3: 0.76
Assigning mean value to entropy: 1.65
Assigning mean value to ranked_MI: 0.48
**************************************************
1 members: 1428 clusters
2 members: 226 clusters
3 members: 57 clusters
4 members: 24 clusters
5 members: 18 clusters
7 members: 8 clusters
6 members: 6 clusters
9 members: 3 clusters
8 members: 2 clusters
36 members: 1 clusters
10 members: 1 clusters
No. UniProtID: 2423, No. SAVs: 20361, and No. clusters: 1774
No. pathogenic SAVs: 13626 and benign SAVs: 6735
**************************************************
> Deleting cluster P29033 from data_sorted
No. clusters: 1773
No. SAVs after deleting P29033: 20295
**************************************************
> Adding cluster P29033 to the test set
Test set percent = 10.03% is larger than 10%: Breaking the loop
No. adding to test set: 34
Cluster IDs added to the test set: [67, 5, 11, 17, 23, 29, 35, 41, 47, 53, 59, 65, 72, 78, 84, 90, 96, 102, 108, 114, 120, 126, 132, 138, 144, 150, 156, 162, 168, 174, 180, 186, 192, 198]
Member IDs added to the test set: ['P29033', 'P07101', 'Q8IWU9', 'P00439', 'Q9UHC9', 'O15118', 'P22304', 'P30613', 'P14618', 'P35520', 'P11509', 'Q16696', 'P05181', 'P20813', 'P11712', 'P10632', 'P33261', 'P00966', 'P11413', 'Q93099', 'P15848', 'P54802', 'P60484', 'Q06124', 'P09619', 'P16234', 'P10721', 'P07333', 'P78504', 'Q9NR61', 'P52701', 'Q15831', 'P08559', 'P06400', 'P00156', 'P78527', 'Q14353', 'Q13224', 'Q12879', 'Q9H251', 'P51648', 'P30838', 'P18074', 'O94759', 'Q8TD43', 'P00813', 'O14733', 'P36507', 'P45985', 'Q02750', 'Q96L73', 'O43240', 'P06870', 'P07288', 'P20151', 'O60259', 'Q9Y5K2', 'P23946', 'P07477', 'Q92876', 'P46597', 'P03891']
> Delete test indices from data_sorted
No. clusters after deleting test indices: 1740
No. SAVs after deleting test indices: 18596
**************************************************
> Adding cluster Q16874 P55735 P57740 Q12769 Q9BW27 to the training set
Q16874 SAVs: 71
Q16874 SAV coords: P55735 172 S L
Q16874 SAV labels: 0
**************************************************
> Adding cluster P04745 to the validation set
Fold 0: 
         Train: n_SAVs = 14651, % SAVs = 71.96%, n_pathogenic = 8967, n_benign = 5684, ratio = 1.58:1, n_clusters = 1652, n_members = 2189
         Val: n_SAVs = 3667, % SAVs = 18.01%, n_pathogenic = 3010, n_benign = 657, ratio = 4.58:1, n_clusters = 88, n_members = 168
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 1: 
         Train: n_SAVs = 14652, % SAVs = 71.96%, n_pathogenic = 9287, n_benign = 5365, ratio = 1.73:1, n_clusters = 1541, n_members = 2039
         Val: n_SAVs = 3666, % SAVs = 18.01%, n_pathogenic = 2690, n_benign = 976, ratio = 2.76:1, n_clusters = 199, n_members = 318
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 2: 
         Train: n_SAVs = 14653, % SAVs = 71.97%, n_pathogenic = 10113, n_benign = 4540, ratio = 2.23:1, n_clusters = 1403, n_members = 1861
         Val: n_SAVs = 3665, % SAVs = 18.00%, n_pathogenic = 1864, n_benign = 1801, ratio = 1.03:1, n_clusters = 337, n_members = 496
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 3: 
         Train: n_SAVs = 14653, % SAVs = 71.97%, n_pathogenic = 9852, n_benign = 4801, ratio = 2.05:1, n_clusters = 1255, n_members = 1733
         Val: n_SAVs = 3665, % SAVs = 18.00%, n_pathogenic = 2125, n_benign = 1540, ratio = 1.38:1, n_clusters = 485, n_members = 624
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
Fold 4: 
         Train: n_SAVs = 14663, % SAVs = 72.02%, n_pathogenic = 9689, n_benign = 4974, ratio = 1.95:1, n_clusters = 1109, n_members = 1606
         Val: n_SAVs = 3655, % SAVs = 17.95%, n_pathogenic = 2288, n_benign = 1367, ratio = 1.67:1, n_clusters = 631, n_members = 751
         Test: n_SAVs = 2043, % SAVs = 10.03%, n_pathogenic = 1649, n_benign = 394, ratio = 4.19:1, n_clusters = 34, n_members = 62
**************************************************
Missing values in the dataframe:
labels: 		 83
entropy: 		 6
ranked_MI: 		 6
No. Unknown SAVs 25 (benign), 22 (pathogenic), and 83 (NaN)
Input Layer: 33
Model Configuration: 
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Layer   | Activation | Batch Norm | Dropout Rate |  Initializer   | L1 |   L2   | N Neurons |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
|   Input   |     -      |     -      |     0.0      |       -        | -  |   -    |     33    |
| hidden_00 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_01 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_02 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_03 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_04 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     33    |
| hidden_05 |    gelu    |   False    |     0.0      | glorot_uniform | 0  | 0.0001 |     10    |
|   Output  |  softmax   |     -      |      -       |       -        | -  |   -    |     2     |
+-----------+------------+------------+--------------+----------------+----+--------+-----------+
Training Configuration: 
+-----------+------------+----------+--------------------------+---------------------+
|  Training | Batch Size | N Epochs |           Loss           |       Metrics       |
+-----------+------------+----------+--------------------------+---------------------+
|  Training |    300     |   300    | categorical_crossentropy | ['accuracy', 'AUC'] |
| Optimizer |   5e-05    |  Nadam   |            -             |          -          |
+-----------+------------+----------+--------------------------+---------------------+
Start from epoch: 10
Fold 1 - Train: 14pos + 14neg, Val: 6pos + 8neg, Test: 2pos + 3neg)
Train: ['P29033 4 G D' 'P29033 34 M T' 'P29033 203 I T' 'P29033 37 V I'
 'P29033 165 R W' 'P29033 170 N S' 'P29033 206 N S' 'P29033 16 H Y'
 'P29033 111 I T' 'P29033 59 G A' 'P29033 75 R Q' 'P29033 205 L V'
 'P29033 83 F L' 'P29033 121 I V' 'P29033 184 R Q' 'P29033 210 L V'
 'P29033 163 M T' 'P29033 143 R W' 'P29033 95 V M' 'P29033 202 C F'
 'P29033 195 M T' 'P29033 143 R Q' 'P29033 214 L V' 'P29033 123 T N'
 'P29033 170 N K' 'P29033 107 I L' 'P29033 197 A T' 'P29033 44 W C']
Val: ['P29033 156 V I' 'P29033 161 F S' 'P29033 215 I M' 'P29033 197 A S'
 'P29033 179 D N' 'P29033 153 V I' 'P29033 27 V I' 'P29033 114 E G'
 'P29033 168 K R' 'P29033 217 Y D' 'P29033 127 R H' 'P29033 90 L P'
 'P29033 75 R W' 'P29033 84 V L']
Test: ['P29033 100 H Q' 'P29033 50 D N' 'P29033 115 F V' 'P29033 44 W S'
 'P29033 4 G V']
Fold 2 - Train: 13pos + 15neg, Val: 7pos + 7neg, Test: 2pos + 3neg)
Train: ['P29033 156 V I' 'P29033 161 F S' 'P29033 215 I M' 'P29033 34 M T'
 'P29033 197 A S' 'P29033 203 I T' 'P29033 37 V I' 'P29033 170 N S'
 'P29033 206 N S' 'P29033 179 D N' 'P29033 111 I T' 'P29033 75 R Q'
 'P29033 153 V I' 'P29033 27 V I' 'P29033 121 I V' 'P29033 184 R Q'
 'P29033 114 E G' 'P29033 210 L V' 'P29033 168 K R' 'P29033 217 Y D'
 'P29033 127 R H' 'P29033 143 R Q' 'P29033 123 T N' 'P29033 197 A T'
 'P29033 90 L P' 'P29033 75 R W' 'P29033 84 V L' 'P29033 44 W C']
Val: ['P29033 4 G D' 'P29033 165 R W' 'P29033 16 H Y' 'P29033 59 G A'
 'P29033 205 L V' 'P29033 83 F L' 'P29033 163 M T' 'P29033 143 R W'
 'P29033 95 V M' 'P29033 202 C F' 'P29033 195 M T' 'P29033 214 L V'
 'P29033 170 N K' 'P29033 107 I L']
Test: ['P29033 100 H Q' 'P29033 50 D N' 'P29033 115 F V' 'P29033 44 W S'
 'P29033 4 G V']
Fold 3 - Train: 13pos + 15neg, Val: 7pos + 7neg, Test: 2pos + 3neg)
Train: ['P29033 156 V I' 'P29033 4 G D' 'P29033 161 F S' 'P29033 215 I M'
 'P29033 197 A S' 'P29033 165 R W' 'P29033 179 D N' 'P29033 16 H Y'
 'P29033 59 G A' 'P29033 205 L V' 'P29033 83 F L' 'P29033 153 V I'
 'P29033 27 V I' 'P29033 114 E G' 'P29033 168 K R' 'P29033 163 M T'
 'P29033 143 R W' 'P29033 95 V M' 'P29033 202 C F' 'P29033 217 Y D'
 'P29033 127 R H' 'P29033 195 M T' 'P29033 214 L V' 'P29033 170 N K'
 'P29033 107 I L' 'P29033 90 L P' 'P29033 75 R W' 'P29033 84 V L']
Val: ['P29033 34 M T' 'P29033 203 I T' 'P29033 37 V I' 'P29033 170 N S'
 'P29033 206 N S' 'P29033 111 I T' 'P29033 75 R Q' 'P29033 121 I V'
 'P29033 184 R Q' 'P29033 210 L V' 'P29033 143 R Q' 'P29033 123 T N'
 'P29033 197 A T' 'P29033 44 W C']
Test: ['P29033 100 H Q' 'P29033 50 D N' 'P29033 115 F V' 'P29033 44 W S'
 'P29033 4 G V']
=.= No. 0
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.51, R20000_val_accuracy: 77.34%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.43, R20000_test_accuracy: 82.09%, R20000_test_auc: 0.90, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.44, val_accuracy: 85.71%, val_auc: 0.88, val_precision: 0.86, val_recall: 0.86, test_loss: 0.35, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 1 after - R20000_val_loss: 0.68, R20000_val_accuracy: 71.83%, R20000_val_auc: 0.78, R20000_val_precision: 0.72, R20000_val_recall: 0.72, R20000_test_loss: 0.50, R20000_test_accuracy: 79.34%, R20000_test_auc: 0.87, R20000_test_precision: 0.79, R20000_test_recall: 0.79, val_loss: 0.33, val_accuracy: 85.71%, val_auc: 0.96, val_precision: 0.86, val_recall: 0.86, test_loss: 0.12, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.083	0
P29033 50 D N	0.713	1
P29033 115 F V	0.019	0
P29033 44 W S	0.986	1
P29033 4 G V	0.092	0
Predictions on val data
P29033 156 V I	0.008	0
P29033 161 F S	0.958	1
P29033 215 I M	0.016	0
P29033 197 A S	0.092	0
P29033 179 D N	0.815	1
P29033 153 V I	0.023	0
P29033 27 V I	0.725	1
P29033 114 E G	0.041	0
P29033 168 K R	0.202	0
P29033 217 Y D	0.045	0
P29033 127 R H	0.029	0
P29033 90 L P	0.946	1
P29033 75 R W	0.955	1
P29033 84 V L	0.942	1
Fold 2 before - R20000_val_loss: 0.51, R20000_val_accuracy: 77.34%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.43, R20000_test_accuracy: 82.09%, R20000_test_auc: 0.90, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.38, val_accuracy: 85.71%, val_auc: 0.95, val_precision: 0.86, val_recall: 0.86, test_loss: 0.35, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 2 after - R20000_val_loss: 0.70, R20000_val_accuracy: 71.04%, R20000_val_auc: 0.77, R20000_val_precision: 0.71, R20000_val_recall: 0.71, R20000_test_loss: 0.50, R20000_test_accuracy: 78.95%, R20000_test_auc: 0.87, R20000_test_precision: 0.79, R20000_test_recall: 0.79, val_loss: 0.25, val_accuracy: 85.71%, val_auc: 0.97, val_precision: 0.86, val_recall: 0.86, test_loss: 0.12, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.177	0
P29033 50 D N	0.840	1
P29033 115 F V	0.023	0
P29033 44 W S	0.989	1
P29033 4 G V	0.128	0
Predictions on val data
P29033 4 G D	0.253	0
P29033 165 R W	0.615	1
P29033 16 H Y	0.609	1
P29033 59 G A	0.972	1
P29033 205 L V	0.920	1
P29033 83 F L	0.387	0
P29033 163 M T	0.899	1
P29033 143 R W	0.963	1
P29033 95 V M	0.881	1
P29033 202 C F	0.950	1
P29033 195 M T	0.949	1
P29033 214 L V	0.012	0
P29033 170 N K	0.109	0
P29033 107 I L	0.001	0
Fold 3 before - R20000_val_loss: 0.51, R20000_val_accuracy: 77.34%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.43, R20000_test_accuracy: 82.09%, R20000_test_auc: 0.90, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.40, val_accuracy: 85.71%, val_auc: 0.91, val_precision: 0.86, val_recall: 0.86, test_loss: 0.35, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 3 after - R20000_val_loss: 0.53, R20000_val_accuracy: 76.03%, R20000_val_auc: 0.83, R20000_val_precision: 0.76, R20000_val_recall: 0.76, R20000_test_loss: 0.44, R20000_test_accuracy: 81.60%, R20000_test_auc: 0.89, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.39, val_accuracy: 85.71%, val_auc: 0.91, val_precision: 0.86, val_recall: 0.86, test_loss: 0.31, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.322	0
P29033 50 D N	0.597	1
P29033 115 F V	0.121	0
P29033 44 W S	0.930	1
P29033 4 G V	0.312	0
Predictions on val data
P29033 34 M T	0.299	0
P29033 203 I T	0.801	1
P29033 37 V I	0.543	1
P29033 170 N S	0.062	0
P29033 206 N S	0.784	1
P29033 111 I T	0.032	0
P29033 75 R Q	0.809	1
P29033 121 I V	0.028	0
P29033 184 R Q	0.835	1
P29033 210 L V	0.377	0
P29033 143 R Q	0.877	1
P29033 123 T N	0.058	0
P29033 197 A T	0.302	0
P29033 44 W C	0.917	1
Before Training
-----------------------------------------------------------------R20000_val_loss	0.51±0.00, R20000_val_accuracy	77.34±0.00%, 
R20000_test_loss	0.43±0.00, R20000_test_accuracy	82.09±0.00%, 
val_loss	0.40±0.02, val_accuracy	85.71±0.00%, 
test_loss	0.35±0.00, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.64±0.05, R20000_val_accuracy	72.97±1.55%, 
R20000_test_loss	0.48±0.02, R20000_test_accuracy	79.96±0.82%, 
val_loss	0.33±0.04, val_accuracy	85.71±0.00%, 
test_loss	0.19±0.06, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------
=.= No. 1
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.44, R20000_val_accuracy: 81.78%, R20000_val_auc: 0.89, R20000_val_precision: 0.82, R20000_val_recall: 0.82, R20000_test_loss: 0.39, R20000_test_accuracy: 84.39%, R20000_test_auc: 0.92, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.49, val_accuracy: 85.71%, val_auc: 0.89, val_precision: 0.86, val_recall: 0.86, test_loss: 0.38, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 1 after - R20000_val_loss: 0.47, R20000_val_accuracy: 80.63%, R20000_val_auc: 0.88, R20000_val_precision: 0.81, R20000_val_recall: 0.81, R20000_test_loss: 0.43, R20000_test_accuracy: 82.48%, R20000_test_auc: 0.90, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.37, val_accuracy: 85.71%, val_auc: 0.94, val_precision: 0.86, val_recall: 0.86, test_loss: 0.15, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.101	0
P29033 50 D N	0.697	1
P29033 115 F V	0.026	0
P29033 44 W S	0.986	1
P29033 4 G V	0.165	0
Predictions on val data
P29033 156 V I	0.018	0
P29033 161 F S	0.945	1
P29033 215 I M	0.033	0
P29033 197 A S	0.089	0
P29033 179 D N	0.789	1
P29033 153 V I	0.042	0
P29033 27 V I	0.766	1
P29033 114 E G	0.079	0
P29033 168 K R	0.252	0
P29033 217 Y D	0.097	0
P29033 127 R H	0.053	0
P29033 90 L P	0.921	1
P29033 75 R W	0.943	1
P29033 84 V L	0.921	1
Fold 2 before - R20000_val_loss: 0.44, R20000_val_accuracy: 81.78%, R20000_val_auc: 0.89, R20000_val_precision: 0.82, R20000_val_recall: 0.82, R20000_test_loss: 0.39, R20000_test_accuracy: 84.39%, R20000_test_auc: 0.92, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.39, val_accuracy: 78.57%, val_auc: 0.94, val_precision: 0.79, val_recall: 0.79, test_loss: 0.38, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 2 after - R20000_val_loss: 0.51, R20000_val_accuracy: 79.81%, R20000_val_auc: 0.87, R20000_val_precision: 0.80, R20000_val_recall: 0.80, R20000_test_loss: 0.44, R20000_test_accuracy: 81.94%, R20000_test_auc: 0.90, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.25, val_accuracy: 92.86%, val_auc: 0.96, val_precision: 0.93, val_recall: 0.93, test_loss: 0.13, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.129	0
P29033 50 D N	0.847	1
P29033 115 F V	0.020	0
P29033 44 W S	0.993	1
P29033 4 G V	0.217	0
Predictions on val data
P29033 4 G D	0.337	0
P29033 165 R W	0.700	1
P29033 16 H Y	0.420	0
P29033 59 G A	0.977	1
P29033 205 L V	0.913	1
P29033 83 F L	0.346	0
P29033 163 M T	0.887	1
P29033 143 R W	0.963	1
P29033 95 V M	0.839	1
P29033 202 C F	0.935	1
P29033 195 M T	0.952	1
P29033 214 L V	0.022	0
P29033 170 N K	0.129	0
P29033 107 I L	0.002	0
Fold 3 before - R20000_val_loss: 0.44, R20000_val_accuracy: 81.78%, R20000_val_auc: 0.89, R20000_val_precision: 0.82, R20000_val_recall: 0.82, R20000_test_loss: 0.39, R20000_test_accuracy: 84.39%, R20000_test_auc: 0.92, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.39, val_accuracy: 85.71%, val_auc: 0.93, val_precision: 0.86, val_recall: 0.86, test_loss: 0.38, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 3 after - R20000_val_loss: 0.44, R20000_val_accuracy: 81.48%, R20000_val_auc: 0.88, R20000_val_precision: 0.81, R20000_val_recall: 0.81, R20000_test_loss: 0.40, R20000_test_accuracy: 84.34%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.39, val_accuracy: 85.71%, val_auc: 0.92, val_precision: 0.86, val_recall: 0.86, test_loss: 0.35, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.305	0
P29033 50 D N	0.613	1
P29033 115 F V	0.133	0
P29033 44 W S	0.933	1
P29033 4 G V	0.458	0
Predictions on val data
P29033 34 M T	0.277	0
P29033 203 I T	0.745	1
P29033 37 V I	0.528	1
P29033 170 N S	0.074	0
P29033 206 N S	0.791	1
P29033 111 I T	0.034	0
P29033 75 R Q	0.785	1
P29033 121 I V	0.040	0
P29033 184 R Q	0.806	1
P29033 210 L V	0.359	0
P29033 143 R Q	0.857	1
P29033 123 T N	0.084	0
P29033 197 A T	0.279	0
P29033 44 W C	0.926	1
Before Training
-----------------------------------------------------------------R20000_val_loss	0.44±0.00, R20000_val_accuracy	81.78±0.00%, 
R20000_test_loss	0.39±0.00, R20000_test_accuracy	84.39±0.00%, 
val_loss	0.42±0.03, val_accuracy	83.33±2.38%, 
test_loss	0.38±0.00, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.47±0.02, R20000_val_accuracy	80.64±0.48%, 
R20000_test_loss	0.42±0.01, R20000_test_accuracy	82.92±0.73%, 
val_loss	0.34±0.04, val_accuracy	88.10±2.38%, 
test_loss	0.21±0.07, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------
=.= No. 2
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.51, R20000_val_accuracy: 76.89%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.40, R20000_test_accuracy: 83.99%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.50, val_accuracy: 85.71%, val_auc: 0.87, val_precision: 0.86, val_recall: 0.86, test_loss: 0.41, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
Fold 1 after - R20000_val_loss: 0.56, R20000_val_accuracy: 77.46%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.45, R20000_test_accuracy: 81.84%, R20000_test_auc: 0.89, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.38, val_accuracy: 85.71%, val_auc: 0.93, val_precision: 0.86, val_recall: 0.86, test_loss: 0.14, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.071	0
P29033 50 D N	0.710	1
P29033 115 F V	0.029	0
P29033 44 W S	0.985	1
P29033 4 G V	0.170	0
Predictions on val data
P29033 156 V I	0.011	0
P29033 161 F S	0.966	1
P29033 215 I M	0.029	0
P29033 197 A S	0.077	0
P29033 179 D N	0.773	1
P29033 153 V I	0.024	0
P29033 27 V I	0.806	1
P29033 114 E G	0.095	0
P29033 168 K R	0.163	0
P29033 217 Y D	0.101	0
P29033 127 R H	0.036	0
P29033 90 L P	0.949	1
P29033 75 R W	0.948	1
P29033 84 V L	0.952	1
Fold 2 before - R20000_val_loss: 0.51, R20000_val_accuracy: 76.89%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.40, R20000_test_accuracy: 83.99%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.40, val_accuracy: 85.71%, val_auc: 0.92, val_precision: 0.86, val_recall: 0.86, test_loss: 0.41, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
Fold 2 after - R20000_val_loss: 0.55, R20000_val_accuracy: 77.35%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.47, R20000_test_accuracy: 81.20%, R20000_test_auc: 0.88, R20000_test_precision: 0.81, R20000_test_recall: 0.81, val_loss: 0.23, val_accuracy: 92.86%, val_auc: 0.98, val_precision: 0.93, val_recall: 0.93, test_loss: 0.13, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.107	0
P29033 50 D N	0.852	1
P29033 115 F V	0.029	0
P29033 44 W S	0.988	1
P29033 4 G V	0.232	0
Predictions on val data
P29033 4 G D	0.298	0
P29033 165 R W	0.583	1
P29033 16 H Y	0.417	0
P29033 59 G A	0.970	1
P29033 205 L V	0.916	1
P29033 83 F L	0.423	0
P29033 163 M T	0.913	1
P29033 143 R W	0.946	1
P29033 95 V M	0.862	1
P29033 202 C F	0.934	1
P29033 195 M T	0.947	1
P29033 214 L V	0.023	0
P29033 170 N K	0.144	0
P29033 107 I L	0.002	0
Fold 3 before - R20000_val_loss: 0.51, R20000_val_accuracy: 76.89%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.40, R20000_test_accuracy: 83.99%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.40, val_accuracy: 78.57%, val_auc: 0.92, val_precision: 0.79, val_recall: 0.79, test_loss: 0.41, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
Fold 3 after - R20000_val_loss: 0.51, R20000_val_accuracy: 76.86%, R20000_val_auc: 0.84, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.40, R20000_test_accuracy: 83.70%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.39, val_accuracy: 85.71%, val_auc: 0.90, val_precision: 0.86, val_recall: 0.86, test_loss: 0.37, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
P29033 100 H Q	0.304	0
P29033 50 D N	0.607	1
P29033 115 F V	0.152	0
P29033 44 W S	0.942	1
P29033 4 G V	0.508	1
Predictions on val data
P29033 34 M T	0.335	0
P29033 203 I T	0.829	1
P29033 37 V I	0.603	1
P29033 170 N S	0.059	0
P29033 206 N S	0.831	1
P29033 111 I T	0.039	0
P29033 75 R Q	0.796	1
P29033 121 I V	0.037	0
P29033 184 R Q	0.822	1
P29033 210 L V	0.430	0
P29033 143 R Q	0.882	1
P29033 123 T N	0.088	0
P29033 197 A T	0.294	0
P29033 44 W C	0.934	1
Before Training
-----------------------------------------------------------------R20000_val_loss	0.51±0.00, R20000_val_accuracy	76.89±0.00%, 
R20000_test_loss	0.40±0.00, R20000_test_accuracy	83.99±0.00%, 
val_loss	0.43±0.03, val_accuracy	83.33±2.38%, 
test_loss	0.41±0.00, test_accuracy	80.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.54±0.01, R20000_val_accuracy	77.23±0.18%, 
R20000_test_loss	0.44±0.02, R20000_test_accuracy	82.25±0.75%, 
val_loss	0.34±0.05, val_accuracy	88.10±2.38%, 
test_loss	0.22±0.08, test_accuracy	93.33±6.67%, 
-----------------------------------------------------------------
=.= No. 3
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.49, R20000_val_accuracy: 77.76%, R20000_val_auc: 0.86, R20000_val_precision: 0.78, R20000_val_recall: 0.78, R20000_test_loss: 0.39, R20000_test_accuracy: 84.04%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.50, val_accuracy: 78.57%, val_auc: 0.86, val_precision: 0.79, val_recall: 0.79, test_loss: 0.40, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
Fold 1 after - R20000_val_loss: 0.55, R20000_val_accuracy: 77.35%, R20000_val_auc: 0.85, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.45, R20000_test_accuracy: 82.13%, R20000_test_auc: 0.89, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.35, val_accuracy: 85.71%, val_auc: 0.96, val_precision: 0.86, val_recall: 0.86, test_loss: 0.14, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.035	0
P29033 50 D N	0.660	1
P29033 115 F V	0.021	0
P29033 44 W S	0.988	1
P29033 4 G V	0.123	0
Predictions on val data
P29033 156 V I	0.019	0
P29033 161 F S	0.968	1
P29033 215 I M	0.026	0
P29033 197 A S	0.092	0
P29033 179 D N	0.789	1
P29033 153 V I	0.049	0
P29033 27 V I	0.783	1
P29033 114 E G	0.045	0
P29033 168 K R	0.167	0
P29033 217 Y D	0.069	0
P29033 127 R H	0.023	0
P29033 90 L P	0.951	1
P29033 75 R W	0.958	1
P29033 84 V L	0.939	1
Fold 2 before - R20000_val_loss: 0.49, R20000_val_accuracy: 77.76%, R20000_val_auc: 0.86, R20000_val_precision: 0.78, R20000_val_recall: 0.78, R20000_test_loss: 0.39, R20000_test_accuracy: 84.04%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.43, val_accuracy: 85.71%, val_auc: 0.89, val_precision: 0.86, val_recall: 0.86, test_loss: 0.40, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
Fold 2 after - R20000_val_loss: 0.56, R20000_val_accuracy: 77.35%, R20000_val_auc: 0.85, R20000_val_precision: 0.77, R20000_val_recall: 0.77, R20000_test_loss: 0.45, R20000_test_accuracy: 81.74%, R20000_test_auc: 0.89, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.22, val_accuracy: 92.86%, val_auc: 0.99, val_precision: 0.93, val_recall: 0.93, test_loss: 0.12, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.060	0
P29033 50 D N	0.828	1
P29033 115 F V	0.026	0
P29033 44 W S	0.991	1
P29033 4 G V	0.225	0
Predictions on val data
P29033 4 G D	0.370	0
P29033 165 R W	0.529	1
P29033 16 H Y	0.340	0
P29033 59 G A	0.971	1
P29033 205 L V	0.903	1
P29033 83 F L	0.372	0
P29033 163 M T	0.881	1
P29033 143 R W	0.957	1
P29033 95 V M	0.829	1
P29033 202 C F	0.933	1
P29033 195 M T	0.942	1
P29033 214 L V	0.016	0
P29033 170 N K	0.143	0
P29033 107 I L	0.002	0
Fold 3 before - R20000_val_loss: 0.49, R20000_val_accuracy: 77.76%, R20000_val_auc: 0.86, R20000_val_precision: 0.78, R20000_val_recall: 0.78, R20000_test_loss: 0.39, R20000_test_accuracy: 84.04%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.40, val_accuracy: 85.71%, val_auc: 0.91, val_precision: 0.86, val_recall: 0.86, test_loss: 0.40, test_accuracy: 80.00%, test_auc: 0.96, test_precision: 0.80, test_recall: 0.80
Fold 3 after - R20000_val_loss: 0.49, R20000_val_accuracy: 78.01%, R20000_val_auc: 0.86, R20000_val_precision: 0.78, R20000_val_recall: 0.78, R20000_test_loss: 0.41, R20000_test_accuracy: 83.85%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.40, val_accuracy: 85.71%, val_auc: 0.90, val_precision: 0.86, val_recall: 0.86, test_loss: 0.35, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.190	0
P29033 50 D N	0.534	1
P29033 115 F V	0.113	0
P29033 44 W S	0.934	1
P29033 4 G V	0.468	0
Predictions on val data
P29033 34 M T	0.317	0
P29033 203 I T	0.781	1
P29033 37 V I	0.546	1
P29033 170 N S	0.062	0
P29033 206 N S	0.771	1
P29033 111 I T	0.045	0
P29033 75 R Q	0.767	1
P29033 121 I V	0.031	0
P29033 184 R Q	0.772	1
P29033 210 L V	0.381	0
P29033 143 R Q	0.843	1
P29033 123 T N	0.066	0
P29033 197 A T	0.288	0
P29033 44 W C	0.919	1
Before Training
-----------------------------------------------------------------R20000_val_loss	0.49±0.00, R20000_val_accuracy	77.76±0.00%, 
R20000_test_loss	0.39±0.00, R20000_test_accuracy	84.04±0.00%, 
val_loss	0.44±0.03, val_accuracy	83.33±2.38%, 
test_loss	0.40±0.00, test_accuracy	80.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.53±0.02, R20000_val_accuracy	77.57±0.22%, 
R20000_test_loss	0.44±0.02, R20000_test_accuracy	82.57±0.65%, 
val_loss	0.32±0.05, val_accuracy	88.10±2.38%, 
test_loss	0.20±0.07, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------
=.= No. 4
-----------------------------------------------------------------
Fold 1 before - R20000_val_loss: 0.53, R20000_val_accuracy: 75.21%, R20000_val_auc: 0.83, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.40, R20000_test_accuracy: 83.55%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.46, val_accuracy: 78.57%, val_auc: 0.88, val_precision: 0.79, val_recall: 0.79, test_loss: 0.39, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 1 after - R20000_val_loss: 0.59, R20000_val_accuracy: 75.62%, R20000_val_auc: 0.83, R20000_val_precision: 0.76, R20000_val_recall: 0.76, R20000_test_loss: 0.45, R20000_test_accuracy: 82.04%, R20000_test_auc: 0.89, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.36, val_accuracy: 85.71%, val_auc: 0.94, val_precision: 0.86, val_recall: 0.86, test_loss: 0.16, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.092	0
P29033 50 D N	0.644	1
P29033 115 F V	0.027	0
P29033 44 W S	0.988	1
P29033 4 G V	0.148	0
Predictions on val data
P29033 156 V I	0.017	0
P29033 161 F S	0.955	1
P29033 215 I M	0.028	0
P29033 197 A S	0.116	0
P29033 179 D N	0.697	1
P29033 153 V I	0.038	0
P29033 27 V I	0.787	1
P29033 114 E G	0.050	0
P29033 168 K R	0.216	0
P29033 217 Y D	0.059	0
P29033 127 R H	0.045	0
P29033 90 L P	0.936	1
P29033 75 R W	0.964	1
P29033 84 V L	0.936	1
Fold 2 before - R20000_val_loss: 0.53, R20000_val_accuracy: 75.21%, R20000_val_auc: 0.83, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.40, R20000_test_accuracy: 83.55%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.38, val_accuracy: 85.71%, val_auc: 0.95, val_precision: 0.86, val_recall: 0.86, test_loss: 0.39, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 2 after - R20000_val_loss: 0.61, R20000_val_accuracy: 75.16%, R20000_val_auc: 0.82, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.45, R20000_test_accuracy: 81.64%, R20000_test_auc: 0.89, R20000_test_precision: 0.82, R20000_test_recall: 0.82, val_loss: 0.22, val_accuracy: 92.86%, val_auc: 0.99, val_precision: 0.93, val_recall: 0.93, test_loss: 0.14, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.138	0
P29033 50 D N	0.796	1
P29033 115 F V	0.026	0
P29033 44 W S	0.992	1
P29033 4 G V	0.209	0
Predictions on val data
P29033 4 G D	0.351	0
P29033 165 R W	0.618	1
P29033 16 H Y	0.318	0
P29033 59 G A	0.978	1
P29033 205 L V	0.900	1
P29033 83 F L	0.273	0
P29033 163 M T	0.881	1
P29033 143 R W	0.977	1
P29033 95 V M	0.847	1
P29033 202 C F	0.940	1
P29033 195 M T	0.946	1
P29033 214 L V	0.029	0
P29033 170 N K	0.160	0
P29033 107 I L	0.002	0
Fold 3 before - R20000_val_loss: 0.53, R20000_val_accuracy: 75.21%, R20000_val_auc: 0.83, R20000_val_precision: 0.75, R20000_val_recall: 0.75, R20000_test_loss: 0.40, R20000_test_accuracy: 83.55%, R20000_test_auc: 0.91, R20000_test_precision: 0.84, R20000_test_recall: 0.84, val_loss: 0.40, val_accuracy: 85.71%, val_auc: 0.92, val_precision: 0.86, val_recall: 0.86, test_loss: 0.39, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
Fold 3 after - R20000_val_loss: 0.54, R20000_val_accuracy: 75.62%, R20000_val_auc: 0.83, R20000_val_precision: 0.76, R20000_val_recall: 0.76, R20000_test_loss: 0.42, R20000_test_accuracy: 82.92%, R20000_test_auc: 0.90, R20000_test_precision: 0.83, R20000_test_recall: 0.83, val_loss: 0.40, val_accuracy: 78.57%, val_auc: 0.91, val_precision: 0.79, val_recall: 0.79, test_loss: 0.30, test_accuracy: 100.00%, test_auc: 1.00, test_precision: 1.00, test_recall: 1.00
P29033 100 H Q	0.205	0
P29033 50 D N	0.526	1
P29033 115 F V	0.084	0
P29033 44 W S	0.955	1
P29033 4 G V	0.328	0
Predictions on val data
P29033 34 M T	0.215	0
P29033 203 I T	0.739	1
P29033 37 V I	0.421	0
P29033 170 N S	0.074	0
P29033 206 N S	0.773	1
P29033 111 I T	0.018	0
P29033 75 R Q	0.821	1
P29033 121 I V	0.024	0
P29033 184 R Q	0.814	1
P29033 210 L V	0.266	0
P29033 143 R Q	0.884	1
P29033 123 T N	0.050	0
P29033 197 A T	0.254	0
P29033 44 W C	0.955	1
Before Training
-----------------------------------------------------------------R20000_val_loss	0.53±0.00, R20000_val_accuracy	75.21±0.00%, 
R20000_test_loss	0.40±0.00, R20000_test_accuracy	83.55±0.00%, 
val_loss	0.41±0.02, val_accuracy	83.33±2.38%, 
test_loss	0.39±0.00, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------After Training
R20000_val_loss	0.58±0.02, R20000_val_accuracy	75.47±0.16%, 
R20000_test_loss	0.44±0.01, R20000_test_accuracy	82.20±0.38%, 
val_loss	0.32±0.05, val_accuracy	85.71±4.12%, 
test_loss	0.20±0.05, test_accuracy	100.00±0.00%, 
-----------------------------------------------------------------
End Time = 20250419-1202
##################################################
